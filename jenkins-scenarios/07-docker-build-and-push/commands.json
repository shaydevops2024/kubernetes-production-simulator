{
  "scenario_id": "07-docker-build-and-push",
  "difficulty": "medium",
  "duration": "15 min",
  "commands": [
    {
      "name": "Step 1: Review the Dockerfile",
      "command": "echo '=== Sample Multi-Stage Dockerfile ==='\ncat << 'DOCKERFILE'\n# Stage 1: Build\nFROM node:18-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\nCOPY src/ ./src/\nRUN npm run build\n\n# Stage 2: Production image\nFROM node:18-alpine AS production\nWORKDIR /app\n\n# Create non-root user\nRUN addgroup -S appgroup && adduser -S appuser -G appgroup\n\n# Copy only built artifacts\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY --from=builder /app/dist ./dist\n\n# Security: run as non-root\nUSER appuser\n\nEXPOSE 3000\nHEALTHCHECK --interval=30s --timeout=3s \\\n  CMD wget -qO- http://localhost:3000/health || exit 1\n\nCMD [\"node\", \"dist/server.js\"]\nDOCKERFILE\necho ''\necho 'Key best practices shown above:'\necho '  1. Multi-stage build: smaller final image (no build tools)'\necho '  2. npm ci: reproducible installs from lock file'\necho '  3. Non-root user: security best practice'\necho '  4. HEALTHCHECK: container self-monitoring'\necho '  5. .dockerignore should exclude node_modules, .git, tests'",
      "description": "Review a production-quality multi-stage Dockerfile",
      "explanation": "A well-designed Dockerfile is the foundation of Docker-based CI/CD. Multi-stage builds keep the final image small by discarding build tools. Running as non-root is a security requirement in most Kubernetes clusters. The HEALTHCHECK directive enables container orchestrators to detect unhealthy instances.",
      "what_it_does": "Displays a complete multi-stage Dockerfile with security best practices including non-root user, health checks, and efficient layering, along with explanations of each practice.",
      "next_step": "Review the Jenkinsfile that builds and pushes this Docker image.",
      "cleanup": false
    },
    {
      "name": "Step 2: Review Jenkinsfile with Docker Stages",
      "command": "echo '=== Jenkinsfile: Docker Build and Push Pipeline ==='\ncat << 'JENKINSFILE'\npipeline {\n    agent any\n\n    environment {\n        REGISTRY     = 'registry.example.com'\n        APP_NAME     = 'my-node-app'\n        IMAGE_TAG    = \"${env.BUILD_NUMBER}\"\n        DOCKER_CREDS = credentials('docker-registry-creds')\n    }\n\n    stages {\n        stage('Checkout') {\n            steps {\n                checkout scm\n            }\n        }\n\n        stage('Run Tests') {\n            steps {\n                sh 'npm ci && npm test'\n            }\n        }\n\n        stage('Docker Build') {\n            steps {\n                sh \"\"\"\n                    docker build \\\\\n                        -t ${REGISTRY}/${APP_NAME}:${IMAGE_TAG} \\\\\n                        -t ${REGISTRY}/${APP_NAME}:latest \\\\\n                        --label \"build.number=${BUILD_NUMBER}\" \\\\\n                        --label \"build.commit=${GIT_COMMIT}\" \\\\\n                        --no-cache .\n                \"\"\"\n            }\n        }\n\n        stage('Docker Push') {\n            steps {\n                sh \"\"\"\n                    echo \\$DOCKER_CREDS_PSW | docker login ${REGISTRY} \\\\\n                        -u \\$DOCKER_CREDS_USR --password-stdin\n                    docker push ${REGISTRY}/${APP_NAME}:${IMAGE_TAG}\n                    docker push ${REGISTRY}/${APP_NAME}:latest\n                    docker logout ${REGISTRY}\n                \"\"\"\n            }\n        }\n\n        stage('Deploy to K8s') {\n            steps {\n                sh \"\"\"\n                    kubectl set image deployment/${APP_NAME} \\\\\n                        app=${REGISTRY}/${APP_NAME}:${IMAGE_TAG} \\\\\n                        -n production\n                    kubectl rollout status deployment/${APP_NAME} \\\\\n                        -n production --timeout=120s\n                \"\"\"\n            }\n        }\n    }\n\n    post {\n        always {\n            sh \"docker rmi ${REGISTRY}/${APP_NAME}:${IMAGE_TAG} || true\"\n        }\n    }\n}\nJENKINSFILE\necho ''\necho 'Important: The post block cleans up local images to prevent'\necho 'disk space issues on Jenkins agents.'",
      "description": "Examine a Jenkinsfile with Docker build, tag, and push stages",
      "explanation": "This pipeline follows the standard Docker CI/CD pattern: test first, build image, push to registry, deploy. The BUILD_NUMBER as image tag ensures every build produces a unique, traceable image. The credentials() function safely injects Docker registry credentials without exposing them in logs. The post block cleans up local images to prevent agent disk issues.",
      "what_it_does": "Displays a complete Jenkinsfile with stages for testing, Docker build with labels, authenticated push to a registry, Kubernetes deployment, and post-build cleanup.",
      "next_step": "Understand the difference between Docker socket mounting and Docker-in-Docker.",
      "cleanup": false
    },
    {
      "name": "Step 3: Understand Docker Socket vs Docker-in-Docker",
      "command": "echo '=== Docker Build Strategies in Jenkins ==='\necho ''\necho '--- Strategy 1: Docker Socket Mount (DooD) ---'\necho '  Mount the host Docker socket into the Jenkins agent container.'\necho ''\necho '  agent {'\necho '      docker {'\necho '          image \"node:18\"'\necho '          args \"-v /var/run/docker.sock:/var/run/docker.sock\"'\necho '      }'\necho '  }'\necho ''\necho '  Pros: Fast, uses host cache, simple setup'\necho '  Cons: Security risk (access to all host containers),'\necho '        port/volume conflicts with host'\necho ''\necho '--- Strategy 2: Docker-in-Docker (DinD) ---'\necho '  Run a separate Docker daemon inside the Jenkins agent.'\necho ''\necho '  // Uses a sidecar DinD container'\necho '  agent {'\necho '      kubernetes {'\necho '          yaml \"\"\"'\necho '          spec:'\necho '            containers:'\necho '            - name: docker'\necho '              image: docker:24-dind'\necho '              securityContext:'\necho '                privileged: true'\necho '          \"\"\"'\necho '      }'\necho '  }'\necho ''\necho '  Pros: Isolated, no host interference, clean environment'\necho '  Cons: Slower (no cache), requires privileged container'\necho ''\necho '--- Strategy 3: Kaniko (Recommended for K8s) ---'\necho '  Build images without Docker daemon, no privileged access.'\necho ''\necho '  container(\"kaniko\") {'\necho '      sh \"/kaniko/executor --context=. --destination=registry/app:tag\"'\necho '  }'\necho ''\necho '  Pros: No Docker daemon needed, no privileged mode, K8s native'\necho '  Cons: Different caching model, some Dockerfile features unsupported'\necho ''\necho '=== Recommendation ==='\necho 'Kaniko for Kubernetes-based Jenkins agents.'\necho 'Docker socket mount for VM-based Jenkins agents.'\necho 'Avoid DinD in production due to privileged container requirement.'",
      "description": "Compare Docker socket mounting, Docker-in-Docker, and Kaniko build strategies",
      "explanation": "Building Docker images inside Jenkins requires careful consideration. Docker socket mounting (DooD) shares the host's Docker daemon, which is fast but creates security risks. Docker-in-Docker (DinD) runs an isolated daemon but requires privileged mode. Kaniko is the modern solution for Kubernetes environments because it builds images without a Docker daemon and without privileged containers.",
      "what_it_does": "Displays a comparison of three Docker build strategies (Docker socket, Docker-in-Docker, Kaniko) with their agent configuration, pros, cons, and a recommendation for each environment.",
      "next_step": "Simulate a Docker build process.",
      "cleanup": false,
      "type": "info"
    },
    {
      "name": "Step 4: Simulate Docker Build",
      "command": "kubectl create namespace jenkins-scenarios --dry-run=client -o yaml | kubectl apply -f - && \\\necho '=== Simulating Docker Build ===' && \\\necho '' && \\\necho \"[Docker Build] Context: .\" && \\\necho \"[Docker Build] Dockerfile: ./Dockerfile\" && \\\necho \"[Docker Build] Tags: registry.example.com/my-node-app:42, registry.example.com/my-node-app:latest\" && \\\necho '' && \\\necho 'Step 1/10: FROM node:18-alpine AS builder' && \\\necho ' ---> Using cache: sha256:a1b2c3d4...' && \\\necho 'Step 2/10: WORKDIR /app' && \\\necho ' ---> Using cache: sha256:e5f6a7b8...' && \\\necho 'Step 3/10: COPY package*.json ./' && \\\necho ' ---> 2.1 MB transferred' && \\\necho 'Step 4/10: RUN npm ci --only=production' && \\\necho ' ---> Installing 147 packages...' && \\\necho ' ---> Done in 12.3s' && \\\necho 'Step 5/10: COPY src/ ./src/' && \\\necho ' ---> 856 KB transferred' && \\\necho 'Step 6/10: RUN npm run build' && \\\necho ' ---> Compiling TypeScript...' && \\\necho ' ---> Build complete: dist/ created' && \\\necho 'Step 7/10: FROM node:18-alpine AS production' && \\\necho ' ---> Fresh layer: sha256:f9e8d7c6...' && \\\necho 'Step 8/10: RUN addgroup -S appgroup && adduser -S appuser -G appgroup' && \\\necho ' ---> User created' && \\\necho 'Step 9/10: COPY --from=builder /app/node_modules ./node_modules' && \\\necho ' ---> 45.2 MB copied from builder stage' && \\\necho 'Step 10/10: COPY --from=builder /app/dist ./dist' && \\\necho ' ---> 1.2 MB copied from builder stage' && \\\necho '' && \\\necho 'Successfully built sha256:abc123def456...' && \\\necho 'Successfully tagged registry.example.com/my-node-app:42' && \\\necho 'Successfully tagged registry.example.com/my-node-app:latest' && \\\necho '' && \\\necho 'Image size comparison:' && \\\necho '  Builder stage (discarded): 312 MB' && \\\necho '  Final production image:     98 MB  (68% smaller!)' && \\\necho '' && \\\necho 'Labels applied:' && \\\necho '  build.number=42' && \\\necho '  build.commit=a1b2c3d4e5f6'",
      "description": "Simulate the Docker build process showing multi-stage build output",
      "explanation": "This simulation shows what a Docker build looks like in a Jenkins pipeline. Multi-stage builds produce a smaller final image because the builder stage (with npm, TypeScript compiler, etc.) is discarded. Only the compiled output and runtime dependencies make it to the production image. Image labels provide traceability back to the Jenkins build and Git commit.",
      "what_it_does": "Creates the jenkins-scenarios namespace and simulates a multi-stage Docker build showing each step, layer caching, the image size reduction from multi-stage builds, and the applied labels.",
      "next_step": "Simulate the Docker tag and push process.",
      "cleanup": false
    },
    {
      "name": "Step 5: Simulate Docker Tag and Push",
      "command": "echo '=== Simulating Docker Tag and Push ===' && \\\necho '' && \\\necho '[Docker Login] Authenticating to registry.example.com...' && \\\necho '  -> Using credentials: docker-registry-creds (Jenkins credential store)' && \\\necho '  -> Login Succeeded' && \\\necho '' && \\\necho '[Docker Push] Pushing registry.example.com/my-node-app:42' && \\\necho '  Layer sha256:a1b2... -> Already exists (base image)' && \\\necho '  Layer sha256:c3d4... -> Pushing [========>          ] 12.4 MB / 45.2 MB' && \\\necho '  Layer sha256:c3d4... -> Pushing [================>  ] 38.1 MB / 45.2 MB' && \\\necho '  Layer sha256:c3d4... -> Pushed  [===================] 45.2 MB' && \\\necho '  Layer sha256:e5f6... -> Pushing [================>  ] 1.0 MB / 1.2 MB' && \\\necho '  Layer sha256:e5f6... -> Pushed  [===================] 1.2 MB' && \\\necho '  42: digest: sha256:789abc123def... size: 1573' && \\\necho '' && \\\necho '[Docker Push] Pushing registry.example.com/my-node-app:latest' && \\\necho '  All layers already exist in registry' && \\\necho '  latest: digest: sha256:789abc123def... size: 1573' && \\\necho '' && \\\necho '[Docker Logout] Removed credentials for registry.example.com' && \\\necho '' && \\\necho 'Tagging strategy summary:' && \\\necho '  :42     -> Immutable tag tied to build number (for rollbacks)' && \\\necho '  :latest -> Floating tag pointing to newest build' && \\\necho '' && \\\necho 'Advanced tagging patterns:' && \\\necho '  :git-a1b2c3d  -> Short commit SHA' && \\\necho '  :v1.2.3       -> Semantic version (from Git tag)' && \\\necho '  :main-42      -> Branch + build number' && \\\necho '  :2024-01-15   -> Date-based tag' && \\\nkubectl create configmap docker-build-info \\\n  --from-literal=image='registry.example.com/my-node-app' \\\n  --from-literal=tag='42' \\\n  --from-literal=digest='sha256:789abc123def' \\\n  --from-literal=size='98 MB' \\\n  --from-literal=pushed-at=\"$(date -Iseconds)\" \\\n  -n jenkins-scenarios \\\n  --dry-run=client -o yaml | kubectl apply -f -",
      "description": "Simulate Docker authentication, push, and explain tagging strategies",
      "explanation": "Docker push sends image layers to the registry. Layers already present are skipped, making subsequent pushes faster. The BUILD_NUMBER tag (:42) is immutable and enables precise rollbacks. The :latest tag is a convenience pointer. The Jenkins credentials() function securely injects registry passwords without exposing them in console output. Always docker logout after pushing to clean up credentials.",
      "what_it_does": "Simulates Docker login, push with layer transfer progress, and logout. Shows multiple tagging strategies and creates a ConfigMap recording the build metadata.",
      "next_step": "Deploy the built image to Kubernetes.",
      "cleanup": false
    },
    {
      "name": "Step 6: Deploy the Built Image to Kubernetes",
      "command": "echo '=== Deploying Built Image to Kubernetes ===' && \\\necho '' && \\\ncat << 'EOF'\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-node-app\n  namespace: jenkins-scenarios\n  labels:\n    app: my-node-app\n  annotations:\n    jenkins.io/build-number: \"42\"\n    jenkins.io/git-commit: \"a1b2c3d4e5f6\"\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-node-app\n  template:\n    metadata:\n      labels:\n        app: my-node-app\n        version: build-42\n    spec:\n      containers:\n      - name: app\n        image: registry.example.com/my-node-app:42\n        ports:\n        - containerPort: 3000\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 10\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 250m\n            memory: 256Mi\nEOF\necho '' && \\\necho '[Deploy] Applying deployment manifest...' && \\\necho '  -> kubectl set image deployment/my-node-app app=registry.example.com/my-node-app:42 -n production' && \\\necho '  -> Waiting for rollout...' && \\\necho '  -> deployment \"my-node-app\" successfully rolled out' && \\\necho '  -> 3/3 replicas updated with new image' && \\\necho '' && \\\necho '[Verify] Running post-deploy health check...' && \\\necho '  -> GET /health -> 200 OK' && \\\necho '  -> Application version: build-42' && \\\necho '  -> Deployment successful' && \\\nkubectl create configmap docker-deploy-info \\\n  --from-literal=deployment='my-node-app' \\\n  --from-literal=image='registry.example.com/my-node-app:42' \\\n  --from-literal=replicas='3' \\\n  --from-literal=status='deployed' \\\n  --from-literal=deployed-at=\"$(date -Iseconds)\" \\\n  -n jenkins-scenarios \\\n  --dry-run=client -o yaml | kubectl apply -f -",
      "description": "Deploy the Docker image to Kubernetes and run health checks",
      "explanation": "After pushing the image to a registry, the pipeline updates the Kubernetes deployment to use the new image tag. The deployment manifest includes annotations tracking the Jenkins build number and Git commit for traceability. Kubernetes performs a rolling update, replacing pods one at a time with the new image. The rollout status command blocks until the update completes or times out.",
      "what_it_does": "Shows a Kubernetes deployment manifest referencing the built image, simulates the rolling update process, runs a post-deploy health check, and creates a ConfigMap recording the deployment details.",
      "next_step": "Verify the complete build-to-deploy pipeline.",
      "cleanup": false
    },
    {
      "name": "Step 7: Verify the Pipeline",
      "command": "echo '=== Docker Build & Push Pipeline Verification ==='\necho ''\necho 'Build metadata:'\nkubectl get configmap docker-build-info -n jenkins-scenarios -o jsonpath='{.data}' | tr ',' '\\n' | tr -d '{}\"'\necho ''\necho 'Deploy metadata:'\nkubectl get configmap docker-deploy-info -n jenkins-scenarios -o jsonpath='{.data}' | tr ',' '\\n' | tr -d '{}\"'\necho ''\necho ''\necho 'Full pipeline timeline:'\necho '  09:00:00  Checkout code from Git'\necho '  09:00:03  npm ci && npm test (unit tests)'\necho '  09:00:45  Docker build (multi-stage, 10 steps)'\necho '  09:01:30  Docker push (2 tags: :42 and :latest)'\necho '  09:02:15  kubectl set image (rolling update)'\necho '  09:02:45  Rollout complete, health check passed'\necho '  09:02:50  Post: cleaned up local Docker images'\necho '  ────────────────────────────────────────────'\necho '  Total pipeline duration: 2 min 50 sec'\necho ''\necho 'All ConfigMaps in jenkins-scenarios:'\nkubectl get configmaps -n jenkins-scenarios --no-headers",
      "description": "Verify all stages of the Docker build-to-deploy pipeline completed successfully",
      "explanation": "A verification step at the end of the pipeline ensures everything was built, pushed, and deployed correctly. By recording metadata in ConfigMaps, we can trace exactly which image is running in the cluster and which Jenkins build produced it. This traceability is critical for debugging production issues and performing rollbacks.",
      "what_it_does": "Displays the build and deploy metadata from ConfigMaps, shows the complete pipeline timeline with durations, and lists all ConfigMaps in the namespace.",
      "next_step": "Review the scenario summary.",
      "cleanup": false
    },
    {
      "name": "Step 8: Scenario Summary",
      "command": "echo '╔══════════════════════════════════════════════════════════════╗'\necho '║        Docker Build & Push - Key Takeaways                  ║'\necho '╠══════════════════════════════════════════════════════════════╣'\necho '║                                                            ║'\necho '║  1. Dockerfile Best Practices:                             ║'\necho '║     -> Multi-stage builds for smaller images               ║'\necho '║     -> Non-root user for security                          ║'\necho '║     -> HEALTHCHECK for self-monitoring                     ║'\necho '║                                                            ║'\necho '║  2. Image Tagging:                                         ║'\necho '║     -> Use BUILD_NUMBER for immutable tags                 ║'\necho '║     -> Add labels for traceability (commit, build #)       ║'\necho '║     -> Never rely solely on :latest in production          ║'\necho '║                                                            ║'\necho '║  3. Build Strategies:                                      ║'\necho '║     -> Docker socket: fast, simple, less secure            ║'\necho '║     -> DinD: isolated but requires privileged              ║'\necho '║     -> Kaniko: best for Kubernetes (no Docker daemon)      ║'\necho '║                                                            ║'\necho '║  4. Security:                                              ║'\necho '║     -> Use credentials() for registry auth                 ║'\necho '║     -> Always docker logout after push                     ║'\necho '║     -> Clean up local images in post block                 ║'\necho '║                                                            ║'\necho '║  5. Pipeline Flow:                                         ║'\necho '║     Test -> Build -> Push -> Deploy -> Verify              ║'\necho '║                                                            ║'\necho '╚══════════════════════════════════════════════════════════════╝'",
      "description": "Review the key concepts learned about Docker build and push in Jenkins",
      "explanation": "Building and pushing Docker images is one of the most common Jenkins pipeline tasks. Understanding multi-stage Dockerfiles, proper tagging strategies, secure credential handling, and build strategies (socket vs DinD vs Kaniko) is essential for any CI/CD pipeline that produces container images.",
      "what_it_does": "Displays a formatted summary of all key Docker build and push concepts covered in this scenario.",
      "next_step": "Clean up all resources created during this scenario.",
      "cleanup": false,
      "type": "info"
    },
    {
      "name": "Step 9: Cleanup",
      "command": "echo 'Cleaning up Docker Build & Push scenario resources...'\nkubectl delete configmap docker-build-info docker-deploy-info -n jenkins-scenarios --ignore-not-found\necho ''\necho 'All Docker Build & Push scenario resources have been removed.'\necho 'The jenkins-scenarios namespace is preserved for other scenarios.'",
      "description": "Remove all resources created during this scenario",
      "explanation": "Cleanup removes the ConfigMaps created during the scenario. The jenkins-scenarios namespace is preserved since other Jenkins scenarios may use it. In a real pipeline, the post block would also clean up local Docker images and temporary files.",
      "what_it_does": "Deletes the docker-build-info and docker-deploy-info ConfigMaps from the jenkins-scenarios namespace.",
      "next_step": "Scenario complete! Try the Parallel Stages and Matrix scenario next to learn about parallel test execution.",
      "cleanup": true
    }
  ]
}
