{
  "scenario_id": "03-remote-state-backend",
  "difficulty": "easy",
  "duration": "15 min",
  "commands": [
    {
      "name": "Step 1: Why Local State Is Dangerous",
      "command": "echo '=== The Problem with Local State ==='\necho ''\necho 'By default, Terraform stores state in a local file: terraform.tfstate'\necho ''\necho 'This causes SERIOUS problems in real teams:'\necho ''\necho '  1. NO COLLABORATION'\necho '     - State lives on one engineer laptop'\necho '     - Other team members cannot see what infrastructure exists'\necho '     - Two people running terraform apply causes state corruption'\necho ''\necho '  2. NO LOCKING'\necho '     - Nothing prevents two people from modifying state simultaneously'\necho '     - Concurrent applies can create duplicate resources or destroy infra'\necho ''\necho '  3. NO DURABILITY'\necho '     - Laptop stolen, hard drive fails = state is GONE'\necho '     - Without state, Terraform cannot manage existing resources'\necho '     - You must manually import every resource or start over'\necho ''\necho '  4. SECRETS EXPOSURE'\necho '     - State contains resource attributes including passwords, keys, tokens'\necho '     - A local file has no encryption at rest or access controls'\necho ''\necho '=== The Solution: Remote State Backend ==='\necho ''\necho '  Remote backends solve ALL of these problems:'\necho '  - Centralized storage (S3, GCS, Azure Blob, Terraform Cloud)'\necho '  - State locking via DynamoDB or native backend support'\necho '  - Encryption at rest (SSE-S3, SSE-KMS)'\necho '  - Access control via IAM policies'\necho '  - Versioning for state history and rollback'",
      "description": "Understand why local Terraform state is dangerous for team collaboration and production use",
      "explanation": "Terraform state is the single source of truth about what infrastructure Terraform manages. When stored locally, it creates a single point of failure and prevents team collaboration. If two engineers run terraform apply against the same infrastructure with different local state files, they will create conflicts, duplicate resources, or destroy each other's work. Remote state backends solve this by storing state in a shared, locked, encrypted, and versioned location.",
      "what_it_does": "Explains the four critical problems with local state (no collaboration, no locking, no durability, secrets exposure) and introduces remote backends as the solution.",
      "next_step": "Next we will create the S3 bucket that stores the Terraform state file.",
      "cleanup": false
    },
    {
      "name": "Step 2: Create the S3 Bucket for State Storage",
      "command": "cat << 'TFEOF'\n# state-bucket.tf - S3 Bucket for Terraform State\n# This bucket stores the terraform.tfstate file remotely.\n# IMPORTANT: Create this bucket BEFORE configuring the backend.\n\nresource \"aws_s3_bucket\" \"terraform_state\" {\n  bucket = \"mycompany-terraform-state-prod\"\n\n  # Prevent accidental deletion of this critical bucket\n  lifecycle {\n    prevent_destroy = true\n  }\n\n  tags = {\n    Name        = \"Terraform State Store\"\n    ManagedBy   = \"terraform\"\n    Environment = \"shared\"\n    Critical    = \"true\"\n  }\n}\n\n# Enable versioning so you can roll back to previous state\nresource \"aws_s3_bucket_versioning\" \"terraform_state\" {\n  bucket = aws_s3_bucket.terraform_state.id\n\n  versioning_configuration {\n    status = \"Enabled\"\n  }\n}\n\n# Encrypt state at rest - it contains sensitive data\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"terraform_state\" {\n  bucket = aws_s3_bucket.terraform_state.id\n\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm = \"aws:kms\"\n    }\n    bucket_key_enabled = true\n  }\n}\n\n# Block ALL public access - state files are sensitive\nresource \"aws_s3_bucket_public_access_block\" \"terraform_state\" {\n  bucket = aws_s3_bucket.terraform_state.id\n\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\nTFEOF",
      "description": "Review the S3 bucket configuration that stores Terraform state with versioning, encryption, and access controls",
      "explanation": "The S3 bucket for state storage needs three critical features: versioning (so you can recover previous state versions if something goes wrong), encryption (because state contains sensitive data like passwords and resource IDs), and public access blocking (because state files should never be publicly accessible). The lifecycle prevent_destroy block prevents accidental deletion of this critical infrastructure. You typically create this bucket in a separate Terraform project or manually via the console before setting up the backend.",
      "what_it_does": "Displays the S3 bucket resource configuration with versioning for state history, KMS encryption for security, public access blocking, and lifecycle protection against accidental deletion.",
      "next_step": "Next we will create the DynamoDB table that provides state locking.",
      "cleanup": false
    },
    {
      "name": "Step 3: Create the DynamoDB Table for State Locking",
      "command": "cat << 'TFEOF'\n# state-lock.tf - DynamoDB Table for State Locking\n# This table prevents concurrent state modifications.\n\nresource \"aws_dynamodb_table\" \"terraform_locks\" {\n  name         = \"terraform-state-locks\"\n  billing_mode = \"PAY_PER_REQUEST\"    # No capacity planning needed\n  hash_key     = \"LockID\"             # Required by Terraform\n\n  attribute {\n    name = \"LockID\"\n    type = \"S\"                        # String type\n  }\n\n  # Enable point-in-time recovery for the lock table\n  point_in_time_recovery {\n    enabled = true\n  }\n\n  tags = {\n    Name        = \"Terraform State Lock Table\"\n    ManagedBy   = \"terraform\"\n    Environment = \"shared\"\n  }\n}\nTFEOF\necho ''\necho '=== How State Locking Works ==='\necho ''\necho '  1. Engineer A runs terraform apply'\necho '     -> Terraform writes a lock record to DynamoDB'\necho '        { \"LockID\": \"mycompany-terraform-state-prod/env/prod/terraform.tfstate\" }'\necho ''\necho '  2. Engineer B runs terraform apply at the same time'\necho '     -> Terraform tries to acquire the lock'\necho '     -> DynamoDB returns: ConditionalCheckFailedException'\necho '     -> Terraform displays:'\necho '        Error: Error acquiring the state lock'\necho '        Lock Info:'\necho '          ID:        a1b2c3d4-e5f6-7890'\necho '          Path:      env/prod/terraform.tfstate'\necho '          Operation: OperationTypeApply'\necho '          Who:       engineer-a@laptop'\necho '          Created:   2024-01-15 14:30:00 UTC'\necho ''\necho '  3. Engineer A apply completes'\necho '     -> Terraform deletes the lock record from DynamoDB'\necho '     -> Engineer B can now acquire the lock'",
      "description": "Create a DynamoDB table for state locking and understand how concurrent access is prevented",
      "explanation": "State locking is critical for team safety. When Terraform acquires a lock, it writes a record to DynamoDB with the LockID as the primary key. DynamoDB conditional writes ensure that only one process can hold the lock at a time. If another engineer tries to run terraform apply while the lock is held, they get a clear error message showing who holds the lock, when it was acquired, and what operation is running. PAY_PER_REQUEST billing mode is ideal because lock operations are infrequent. The LockID attribute must be a string type named exactly 'LockID' -- this is a Terraform convention.",
      "what_it_does": "Shows the DynamoDB table configuration for state locking and walks through a step-by-step scenario of how locking prevents concurrent state modifications between two engineers.",
      "next_step": "Now let's configure the backend block that ties S3 and DynamoDB together.",
      "cleanup": false
    },
    {
      "name": "Step 4: Configure the S3 Backend",
      "command": "cat << 'TFEOF'\n# backend.tf - Remote State Backend Configuration\n# This tells Terraform WHERE to store state and HOW to lock it.\n\nterraform {\n  backend \"s3\" {\n    bucket         = \"mycompany-terraform-state-prod\"\n    key            = \"env/prod/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-state-locks\"\n\n    # Optional: Use a specific KMS key for encryption\n    # kms_key_id = \"arn:aws:kms:us-east-1:123456789012:key/12345678-1234\"\n  }\n}\nTFEOF\necho ''\necho '=== Backend Configuration Explained ==='\necho ''\necho '  bucket         - S3 bucket name where state is stored'\necho '  key            - Path within the bucket (acts like a folder structure)'\necho '  region         - AWS region of the S3 bucket'\necho '  encrypt        - Enable server-side encryption'\necho '  dynamodb_table - DynamoDB table for state locking'\necho ''\necho '=== Multi-Environment State Organization ==='\necho ''\necho '  S3 Bucket: mycompany-terraform-state-prod'\necho '  ├── env/dev/terraform.tfstate'\necho '  ├── env/staging/terraform.tfstate'\necho '  ├── env/prod/terraform.tfstate'\necho '  ├── modules/vpc/terraform.tfstate'\necho '  ├── modules/eks/terraform.tfstate'\necho '  └── modules/rds/terraform.tfstate'\necho ''\necho '  Each \"key\" is a separate state file with its own lock.'\necho '  This lets teams work on different components independently.'\necho ''\necho '=== IMPORTANT ==='\necho '  The backend block CANNOT use variables or locals.'\necho '  All values must be hardcoded or passed via -backend-config flags.'\necho '  Example: terraform init -backend-config=\"key=env/staging/terraform.tfstate\"'",
      "description": "Configure the S3 backend block that connects Terraform to remote state storage with locking",
      "explanation": "The backend block is special in Terraform -- it must be defined inside the terraform {} block and cannot reference variables or locals because it is processed before anything else during terraform init. The 'key' parameter defines the path within the S3 bucket, which allows a single bucket to store state for multiple projects and environments. A common pattern is to use -backend-config flags to override the key per environment, enabling the same code to manage different state files. The encrypt flag ensures state is encrypted in transit and at rest.",
      "what_it_does": "Displays the backend configuration block for S3 with DynamoDB locking, explains each parameter, shows a multi-environment state organization pattern, and notes the restriction that backend blocks cannot use variables.",
      "next_step": "Let's see what happens when you run terraform init with a backend migration.",
      "cleanup": false
    },
    {
      "name": "Step 5: Initialize Backend with Migration",
      "command": "echo '=== terraform init (Backend Migration) ==='\necho ''\necho 'When you add a backend block to an existing project, terraform init'\necho 'detects the change and offers to migrate your state.'\necho ''\necho '$ terraform init'\necho ''\necho 'Initializing the backend...'\necho ''\necho 'Do you want to copy existing state to the new backend?'\necho '  Pre-existing state was found while migrating the previous \"local\"'\necho '  backend to the newly configured \"s3\" backend. No existing state'\necho '  was found in the newly configured \"s3\" backend. Do you want to'\necho '  copy this state to the new \"s3\" backend? Enter \"yes\" to copy'\necho '  and \"no\" to start with an empty state.'\necho ''\necho '  Enter a value: yes'\necho ''\necho 'Successfully configured the backend \"s3\"! Terraform will automatically'\necho 'use this backend unless the backend configuration changes.'\necho ''\necho 'Initializing provider plugins...'\necho '- Reusing previous version of hashicorp/aws from the dependency lock file'\necho '- Using previously-installed hashicorp/aws v5.72.1'\necho ''\necho 'Terraform has been successfully initialized!'\necho ''\necho '=== What Just Happened ==='\necho ''\necho '  1. Terraform detected a backend change (local -> s3)'\necho '  2. It uploaded the local terraform.tfstate to S3'\necho '  3. It created a local .terraform/terraform.tfstate with backend metadata'\necho '  4. The local terraform.tfstate is no longer the source of truth'\necho ''\necho '  Your state is now at:'\necho '  s3://mycompany-terraform-state-prod/env/prod/terraform.tfstate'\necho ''\necho '=== Re-initialization scenarios ==='\necho '  terraform init                    # Normal init'\necho '  terraform init -reconfigure       # Reset backend without migration'\necho '  terraform init -migrate-state     # Force migration prompt'\necho '  terraform init -backend-config=.. # Override backend values'",
      "description": "Run terraform init with a backend migration from local to S3 and understand the migration process",
      "explanation": "When Terraform detects that the backend configuration has changed (from local to S3 in this case), it offers to migrate existing state. Answering 'yes' copies the local terraform.tfstate file to the S3 bucket at the specified key path. After migration, the local state file is no longer used -- S3 becomes the single source of truth. The -reconfigure flag skips migration entirely and starts fresh, which is useful when connecting to an existing remote state. The -migrate-state flag explicitly requests migration. Always back up your state before migrating.",
      "what_it_does": "Simulates the terraform init backend migration process, showing the interactive prompt, successful migration output, and explains the four re-initialization scenarios for different use cases.",
      "next_step": "Now let's use terraform state commands to inspect and manage the remote state.",
      "cleanup": false
    },
    {
      "name": "Step 6: Inspect State with terraform state Commands",
      "command": "echo '=== terraform state list ==='\necho ''\necho 'aws_dynamodb_table.terraform_locks'\necho 'aws_s3_bucket.terraform_state'\necho 'aws_s3_bucket_public_access_block.terraform_state'\necho 'aws_s3_bucket_server_side_encryption_configuration.terraform_state'\necho 'aws_s3_bucket_versioning.terraform_state'\necho ''\necho '=== terraform state show aws_s3_bucket.terraform_state ==='\necho ''\necho '# aws_s3_bucket.terraform_state:'\necho 'resource \"aws_s3_bucket\" \"terraform_state\" {'\necho '    arn                         = \"arn:aws:s3:::mycompany-terraform-state-prod\"'\necho '    bucket                      = \"mycompany-terraform-state-prod\"'\necho '    id                          = \"mycompany-terraform-state-prod\"'\necho '    region                      = \"us-east-1\"'\necho '    request_payer               = \"BucketOwner\"'\necho '    tags                        = {'\necho '        \"Critical\"    = \"true\"'\necho '        \"Environment\" = \"shared\"'\necho '        \"ManagedBy\"   = \"terraform\"'\necho '        \"Name\"        = \"Terraform State Store\"'\necho '    }'\necho '}'\necho ''\necho '=== Other Useful State Commands ==='\necho ''\necho '  terraform state list                          # List all resources'\necho '  terraform state show <resource>               # Show one resource'\necho '  terraform state pull                          # Download state as JSON'\necho '  terraform state mv <old> <new>                # Rename/move a resource'\necho '  terraform state rm <resource>                 # Remove from state (not cloud)'\necho '  terraform state push terraform.tfstate.backup # Upload state (DANGEROUS)'\necho ''\necho '  WARNING: state mv, rm, and push modify state directly.'\necho '           Always back up state first: terraform state pull > backup.tfstate'",
      "description": "Use terraform state commands to list, inspect, and manage resources tracked in remote state",
      "explanation": "The terraform state subcommands let you inspect and manipulate what Terraform tracks. 'state list' shows all resource addresses. 'state show' displays the full attributes of a single resource as stored in state. 'state pull' downloads the entire state file as JSON, which is useful for debugging or backup. 'state mv' renames resources without destroying and recreating them (essential during refactoring). 'state rm' removes a resource from state tracking without destroying the actual cloud resource. These commands operate on the remote state directly when a backend is configured.",
      "what_it_does": "Simulates terraform state list and state show commands against remote state, displays all tracked resources with their attributes, and provides a reference of all state management commands with safety warnings.",
      "next_step": "Let's inspect the actual state file structure stored in S3.",
      "cleanup": false
    },
    {
      "name": "Step 7: Inspect the Remote State File",
      "command": "echo '=== terraform state pull (State File from S3) ==='\necho ''\ncat << 'STATEEOF'\n{\n  \"version\": 4,\n  \"terraform_version\": \"1.5.7\",\n  \"serial\": 7,\n  \"lineage\": \"b2c3d4e5-f6a7-8901-bcde-f23456789012\",\n  \"outputs\": {},\n  \"resources\": [\n    {\n      \"mode\": \"managed\",\n      \"type\": \"aws_s3_bucket\",\n      \"name\": \"terraform_state\",\n      \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n      \"instances\": [\n        {\n          \"schema_version\": 0,\n          \"attributes\": {\n            \"id\": \"mycompany-terraform-state-prod\",\n            \"arn\": \"arn:aws:s3:::mycompany-terraform-state-prod\",\n            \"bucket\": \"mycompany-terraform-state-prod\",\n            \"region\": \"us-east-1\"\n          }\n        }\n      ]\n    },\n    {\n      \"mode\": \"managed\",\n      \"type\": \"aws_dynamodb_table\",\n      \"name\": \"terraform_locks\",\n      \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n      \"instances\": [\n        {\n          \"schema_version\": 1,\n          \"attributes\": {\n            \"id\": \"terraform-state-locks\",\n            \"arn\": \"arn:aws:dynamodb:us-east-1:123456789012:table/terraform-state-locks\",\n            \"name\": \"terraform-state-locks\",\n            \"hash_key\": \"LockID\",\n            \"billing_mode\": \"PAY_PER_REQUEST\"\n          }\n        }\n      ]\n    }\n  ]\n}\nSTATEEOF\necho ''\necho '=== Key Fields Explained ==='\necho ''\necho '  version   : State format version (currently 4)'\necho '  serial    : Increments on EVERY state change (optimistic locking)'\necho '  lineage   : UUID that uniquely identifies this state chain'\necho '  resources : Array of all managed infrastructure'\necho ''\necho '  The serial + lineage prevent accidental cross-contamination.'\necho '  If you try to push state with the wrong lineage, Terraform refuses.'\necho '  If the serial is behind the remote, Terraform detects a conflict.'",
      "description": "Examine the remote state file structure pulled from S3 and understand its metadata fields",
      "explanation": "The state file pulled from S3 is identical in format to a local state file -- it is a JSON document with metadata and resource mappings. The critical difference is that S3 provides versioning (you can recover any previous version), encryption (state is encrypted at rest), and access control (IAM policies restrict who can read or write state). The serial number is especially important: every terraform apply increments it, and if two processes try to write state with the same serial, the backend rejects the second write. Combined with DynamoDB locking, this provides strong consistency guarantees.",
      "what_it_does": "Displays the full JSON structure of a state file as it appears in S3, showing the version, serial, lineage, and resource entries, with explanations of how each field prevents state corruption.",
      "next_step": "Let's see how state locking works in practice with a demonstration.",
      "cleanup": false
    },
    {
      "name": "Step 8: Demonstrate State Locking in Action",
      "command": "echo '=== State Locking Demonstration ==='\necho ''\necho 'When terraform apply runs, it creates a DynamoDB lock record:'\necho ''\ncat << 'LOCKEOF'\n{\n  \"LockID\": {\n    \"S\": \"mycompany-terraform-state-prod/env/prod/terraform.tfstate\"\n  },\n  \"Info\": {\n    \"S\": \"{\\\"ID\\\":\\\"a1b2c3d4-lock-uuid\\\",\\\"Operation\\\":\\\"OperationTypeApply\\\",\\\"Info\\\":\\\"\\\",\\\"Who\\\":\\\"engineer@workstation\\\",\\\"Version\\\":\\\"1.5.7\\\",\\\"Created\\\":\\\"2024-01-15T14:30:00.000Z\\\",\\\"Path\\\":\\\"env/prod/terraform.tfstate\\\"}\"\n  }\n}\nLOCKEOF\necho ''\necho '=== Lock Conflict Scenario ==='\necho ''\necho '  Terminal 1 (Engineer A):'\necho '  $ terraform apply'\necho '  Acquiring state lock. This may take a few moments...'\necho '  # Lock acquired, apply proceeds...'\necho ''\necho '  Terminal 2 (Engineer B):'\necho '  $ terraform apply'\necho '  Acquiring state lock. This may take a few moments...'\necho ''\necho '  Error: Error acquiring the state lock'\necho ''\necho '  Error message: ConditionalCheckFailedException: The conditional request failed'\necho '  Lock Info:'\necho '    ID:        a1b2c3d4-lock-uuid'\necho '    Path:      env/prod/terraform.tfstate'\necho '    Operation: OperationTypeApply'\necho '    Who:       engineer@workstation'\necho '    Version:   1.5.7'\necho '    Created:   2024-01-15 14:30:00.000000 +0000 UTC'\necho ''\necho '  Terraform acquires a state lock to protect the state from being'\necho '  written by multiple users at the same time. Please resolve the'\necho '  issue above and try again.'\necho ''\necho '=== Force Unlock (Emergency Only) ==='\necho '  terraform force-unlock a1b2c3d4-lock-uuid'\necho '  WARNING: Only use this if the lock holder crashed and cannot release.'\necho '  Forcing unlock on a running apply can CORRUPT your state.'",
      "description": "See how DynamoDB state locking prevents concurrent modifications with a practical conflict scenario",
      "explanation": "DynamoDB locking uses conditional writes on the LockID key. When Terraform starts an operation, it writes a lock record containing the operation type, who initiated it, and a timestamp. If another process tries to write a lock with the same LockID, DynamoDB rejects it with a ConditionalCheckFailedException. The lock record contains enough information for the blocked user to identify who holds the lock and contact them. The force-unlock command should only be used when the lock holder has crashed (e.g., laptop lost network mid-apply) because force-unlocking during an active apply can cause state corruption.",
      "what_it_does": "Shows the DynamoDB lock record format, walks through a two-engineer conflict scenario with exact error messages, and explains the emergency force-unlock command with safety warnings.",
      "next_step": "Let's wrap up with a summary and cleanup.",
      "cleanup": false
    },
    {
      "name": "Step 9: Cleanup",
      "command": "echo '=== Scenario Complete ==='\necho ''\necho 'In a real environment, the state backend resources are typically'\necho 'NEVER destroyed because they hold the state for all other projects.'\necho ''\necho 'If you needed to tear down the backend (decommission), you would:'\necho '  1. terraform state pull > backup.tfstate      # Backup state'\necho '  2. Migrate all projects to a new backend'\necho '  3. Empty the S3 bucket (versioned objects too)'\necho '  4. terraform destroy                          # Remove resources'\necho ''\necho '=== Summary: Remote State Backend ==='\necho ''\necho 'PROBLEM:'\necho '  Local state has no collaboration, no locking, no durability, no encryption.'\necho ''\necho 'SOLUTION:'\necho '  S3 + DynamoDB backend provides all four.'\necho ''\necho 'COMPONENTS:'\necho '  1. S3 Bucket       - Stores terraform.tfstate (versioned + encrypted)'\necho '  2. DynamoDB Table  - Provides state locking (prevents concurrent writes)'\necho '  3. Backend Block   - Tells Terraform where to find state'\necho ''\necho 'KEY COMMANDS:'\necho '  terraform init              - Initialize/migrate backend'\necho '  terraform state list        - List tracked resources'\necho '  terraform state show <res>  - Inspect a resource'\necho '  terraform state pull        - Download state as JSON'\necho '  terraform state mv          - Rename without recreating'\necho '  terraform state rm          - Untrack without destroying'\necho ''\necho 'BEST PRACTICES:'\necho '  1. One S3 bucket per AWS account, separate keys per project/env'\necho '  2. Enable versioning for state rollback capability'\necho '  3. Enable KMS encryption for sensitive data protection'\necho '  4. Use IAM policies to restrict state access per team'\necho '  5. Never manually edit the state file'\necho '  6. Always back up state before running state mv/rm commands'",
      "description": "Clean up and review what was learned about remote state backends with S3 and DynamoDB",
      "explanation": "Remote state backends are foundational infrastructure for any team using Terraform. The S3 + DynamoDB pattern is the most common backend in AWS environments. The key takeaway is that state management is not optional -- it must be planned and implemented before your first production deployment. State backends should be treated as critical infrastructure with their own lifecycle, backup strategy, and access controls.",
      "what_it_does": "Summarizes the scenario with a complete reference for remote state backends including the problem/solution, components, key commands, and production best practices.",
      "next_step": "Try the next scenario to learn about VPC networking from scratch.",
      "cleanup": true
    }
  ]
}
