{
  "scenario_id": "15-drift-detection-and-compliance",
  "difficulty": "hard",
  "duration": "40 min",
  "commands": [
    {
      "name": "Step 1: Understand Infrastructure Drift",
      "command": "cat << 'TFEOF'\n# =============================================================\n# INFRASTRUCTURE DRIFT - WHAT IT IS AND WHY IT MATTERS\n# =============================================================\n#\n# Drift = the real infrastructure no longer matches what\n# Terraform believes it should be (the state + config).\n#\n# HOW DRIFT HAPPENS:\n#\n#   1. MANUAL CHANGES (most common)\n#      - Someone modifies a security group in the AWS console\n#      - An operator SSH's into a server and installs packages\n#      - A DBA changes RDS parameters directly\n#\n#   2. AUTOMATED EXTERNAL CHANGES\n#      - Auto Scaling adds/removes instances\n#      - AWS applies mandatory patches to managed services\n#      - Another team's Terraform modifies a shared resource\n#\n#   3. PARTIAL APPLIES\n#      - terraform apply fails halfway through\n#      - Network timeout during resource creation\n#      - Rate limiting causes some resources to fail\n#\n# TYPES OF DRIFT:\n#\n#   +-------------------+----------------------------------------+\n#   | Type              | Description                            |\n#   +-------------------+----------------------------------------+\n#   | Configuration     | Resource attributes differ from config |\n#   | State             | State file is stale or corrupted       |\n#   | Desired State     | Config was changed but not applied     |\n#   | Orphaned          | Resource exists but not in state       |\n#   | Missing           | In state but deleted from cloud        |\n#   +-------------------+----------------------------------------+\n#\n# WHY DRIFT IS DANGEROUS:\n#\n#   - Security groups opened wider than intended -> data breach\n#   - Unapproved instance types -> cost overruns\n#   - Missing tags -> billing and compliance violations\n#   - Inconsistent environments -> \"works in staging\" failures\n#   - Unexpected terraform apply behavior -> accidental destroys\n#\n# THE GOAL: Detect drift early, categorize it, and remediate\n# either automatically or through a controlled workflow.\nTFEOF",
      "description": "Understand what infrastructure drift is, how it occurs, and why detecting it is critical for security and compliance.",
      "explanation": "Infrastructure drift occurs when the actual state of cloud resources diverges from what Terraform expects. This can happen through manual console changes, automated processes, or partial applies. Drift is dangerous because it creates security vulnerabilities, cost overruns, and unpredictable behavior during future terraform applies. Categorizing drift by type (configuration, state, orphaned, missing) helps determine the appropriate remediation strategy.",
      "what_it_does": "Displays a comprehensive overview of infrastructure drift including the three main causes (manual changes, automated external changes, partial applies), five categories of drift with descriptions, and the risks that undetected drift poses to security and operations.",
      "next_step": "Next we will use terraform plan with -detailed-exitcode as an automated audit tool.",
      "cleanup": false
    },
    {
      "name": "Step 2: Use terraform plan -detailed-exitcode as Audit Tool",
      "command": "cat << 'TFEOF'\n# =============================================================\n# TERRAFORM PLAN AS AN AUDIT TOOL\n# =============================================================\n# terraform plan -detailed-exitcode returns specific exit codes\n# that tell you whether drift exists. This makes it perfect\n# for automated scheduled audits.\n\n# EXIT CODES:\n#   0 = No changes. Infrastructure matches configuration.\n#   1 = Error. Terraform could not generate a plan.\n#   2 = Changes detected. Infrastructure has drifted.\n\n# ---------- drift-check.sh ----------\n\n#!/bin/bash\n# Automated drift detection script\nset -euo pipefail\n\nTIMESTAMP=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\nWORKSPACE=$(terraform workspace show)\nREPORT_FILE=\"drift-report-${TIMESTAMP}.json\"\n\necho \"[${TIMESTAMP}] Running drift detection for workspace: ${WORKSPACE}\"\n\n# Run terraform plan and capture exit code\nterraform plan -detailed-exitcode -out=plan.tfplan -no-color 2>&1 | tee plan-output.txt\nEXIT_CODE=${PIPESTATUS[0]}\n\ncase $EXIT_CODE in\n  0)\n    echo \"[PASS] No drift detected. Infrastructure matches configuration.\"\n    STATUS=\"clean\"\n    ;;\n  1)\n    echo \"[ERROR] Terraform plan failed. Check configuration.\"\n    STATUS=\"error\"\n    ;;\n  2)\n    echo \"[DRIFT] Changes detected! Infrastructure has drifted.\"\n    STATUS=\"drifted\"\n    # Generate machine-readable drift report\n    terraform show -json plan.tfplan | jq '{\n      timestamp: \"'\"${TIMESTAMP}\"'\",\n      workspace: \"'\"${WORKSPACE}\"'\",\n      status: \"drifted\",\n      changes: {\n        create: [.resource_changes[]? | select(.change.actions | contains([\"create\"])) | .address],\n        update: [.resource_changes[]? | select(.change.actions | contains([\"update\"])) | .address],\n        delete: [.resource_changes[]? | select(.change.actions | contains([\"delete\"])) | .address],\n        replace: [.resource_changes[]? | select(.change.actions | contains([\"delete\", \"create\"])) | .address]\n      },\n      total_changes: (.resource_changes? | length)\n    }' > \"${REPORT_FILE}\"\n    echo \"Drift report saved to: ${REPORT_FILE}\"\n    ;;\nesac\n\n# Send notification on drift\nif [ \"$STATUS\" = \"drifted\" ]; then\n  # Slack webhook notification\n  curl -s -X POST \"${SLACK_WEBHOOK_URL}\" \\\n    -H 'Content-Type: application/json' \\\n    -d '{\"text\": \"Infrastructure drift detected in '\"${WORKSPACE}\"' at '\"${TIMESTAMP}\"'\"}'\n\n  # Or SNS notification\n  aws sns publish \\\n    --topic-arn \"${SNS_TOPIC_ARN}\" \\\n    --subject \"Terraform Drift Detected\" \\\n    --message \"$(cat ${REPORT_FILE})\"\nfi\n\n# SCHEDULING THIS SCRIPT:\n# Cron (every 6 hours):\n#   0 */6 * * * /opt/scripts/drift-check.sh >> /var/log/drift.log 2>&1\n#\n# GitHub Actions (scheduled):\n#   on:\n#     schedule:\n#       - cron: '0 */6 * * *'\n#\n# AWS EventBridge + Lambda:\n#   Rate expression: rate(6 hours)\nTFEOF",
      "description": "Use terraform plan with -detailed-exitcode for automated drift detection and generate machine-readable drift reports.",
      "explanation": "The -detailed-exitcode flag transforms terraform plan from a preview tool into an audit tool. Exit code 0 means clean (no drift), 1 means error, and 2 means drift detected. The script captures the plan output, converts it to a JSON report categorizing changes by type (create, update, delete, replace), and sends notifications via Slack or SNS. Scheduling this script to run every 6 hours provides continuous drift monitoring without any third-party tools.",
      "what_it_does": "Displays a complete drift detection script that runs terraform plan, interprets exit codes, generates a JSON drift report with categorized changes, sends Slack and SNS notifications when drift is found, and includes scheduling options for cron, GitHub Actions, and AWS EventBridge.",
      "next_step": "Next we will learn how to detect and categorize specific drift types from the plan output.",
      "cleanup": false
    },
    {
      "name": "Step 3: Detect and Categorize Drift Types",
      "command": "cat << 'TFEOF'\n# =============================================================\n# CATEGORIZING DRIFT FROM TERRAFORM PLAN OUTPUT\n# =============================================================\n# Not all drift is equal. Categorizing by severity and type\n# determines the response: auto-fix, alert, or investigate.\n\n# ---------- categorize-drift.sh ----------\n\n#!/bin/bash\n# Parse terraform plan JSON and categorize drift\n\n# Generate plan in JSON format\nterraform plan -out=plan.tfplan -no-color > /dev/null 2>&1\nterraform show -json plan.tfplan > plan.json\n\n# CRITICAL DRIFT: Security-related changes\necho \"=== CRITICAL: Security Drift ===\"\njq -r '.resource_changes[]? |\n  select(\n    (.type | test(\"security_group|iam_|kms_|s3_bucket_policy\")) and\n    (.change.actions | contains([\"update\"]))\n  ) |\n  \"  \\(.address): \\(.change.actions | join(\", \"))\"' plan.json\n\n# HIGH: Networking changes\necho \"=== HIGH: Networking Drift ===\"\njq -r '.resource_changes[]? |\n  select(\n    (.type | test(\"vpc|subnet|route|nat_gateway|internet_gateway\")) and\n    (.change.actions | contains([\"update\"]))\n  ) |\n  \"  \\(.address): \\(.change.actions | join(\", \"))\"' plan.json\n\n# MEDIUM: Compute changes\necho \"=== MEDIUM: Compute Drift ===\"\njq -r '.resource_changes[]? |\n  select(\n    (.type | test(\"instance|launch_template|autoscaling\")) and\n    (.change.actions | contains([\"update\"]))\n  ) |\n  \"  \\(.address): \\(.change.actions | join(\", \"))\"' plan.json\n\n# LOW: Tag-only changes\necho \"=== LOW: Tag Drift ===\"\njq -r '.resource_changes[]? |\n  select(\n    (.change.actions | contains([\"update\"])) and\n    (.change.before | keys | . - [\"tags\", \"tags_all\"] | length) ==\n    (.change.after  | keys | . - [\"tags\", \"tags_all\"] | length)\n  ) |\n  \"  \\(.address): tag changes only\"' plan.json\n\n# ORPHANED RESOURCES: In cloud but not in state\n# These require terraform import to bring under management\necho \"=== ORPHANED: Resources to Import ===\"\necho \"  Use 'aws resourcegroupstaggingapi get-resources' to find\"\necho \"  resources tagged with ManagedBy=terraform that are not\"\necho \"  tracked in the current state file.\"\n\n# MISSING RESOURCES: In state but deleted from cloud\necho \"=== MISSING: Resources to Recreate ===\"\njq -r '.resource_changes[]? |\n  select(.change.actions | contains([\"create\"])) |\n  select(.change.before == null) |\n  \"  \\(.address): will be recreated\"' plan.json\n\n# SEVERITY RESPONSE MATRIX:\n#\n#   Severity  | Response          | SLA\n#   ----------|-------------------|--------\n#   CRITICAL  | Page on-call      | 15 min\n#   HIGH      | Alert team lead   | 1 hour\n#   MEDIUM    | Create ticket     | 24 hours\n#   LOW       | Auto-remediate    | Next run\nTFEOF",
      "description": "Parse terraform plan JSON output to categorize drift by severity: critical (security), high (networking), medium (compute), and low (tags).",
      "explanation": "Different types of drift require different responses. Security group and IAM changes are critical because they could indicate a breach or unauthorized access, warranting immediate investigation. Networking changes are high severity because they affect connectivity. Compute drift is medium because it usually reflects scaling or configuration updates. Tag-only changes are low severity and can often be auto-remediated. The severity response matrix maps each category to an action and SLA, ensuring the right urgency for each type of drift.",
      "what_it_does": "Displays a drift categorization script that parses terraform plan JSON, groups changes by severity level (critical/security, high/networking, medium/compute, low/tags), identifies orphaned and missing resources, and provides a severity response matrix with SLAs.",
      "next_step": "Next we will write OPA/Rego policies for compliance checks.",
      "cleanup": false
    },
    {
      "name": "Step 4: Write OPA/Rego Policies for Compliance Checks",
      "command": "cat << 'TFEOF'\n# =============================================================\n# OPA/REGO POLICIES FOR TERRAFORM COMPLIANCE\n# =============================================================\n# Open Policy Agent (OPA) with Rego language lets you define\n# policies that Terraform plans must pass before apply.\n# Use conftest or OPA directly to evaluate plan JSON.\n\n# ---------- policy/terraform.rego ----------\n\npackage terraform\n\nimport input as tfplan\n\n# RULE 1: Deny public S3 buckets\ndeny[msg] {\n  resource := tfplan.resource_changes[_]\n  resource.type == \"aws_s3_bucket\"\n  resource.change.after.acl == \"public-read\"\n  msg := sprintf(\n    \"DENY: S3 bucket '%s' has public-read ACL. All buckets must be private.\",\n    [resource.address]\n  )\n}\n\n# RULE 2: Deny overly permissive security groups\ndeny[msg] {\n  resource := tfplan.resource_changes[_]\n  resource.type == \"aws_security_group_rule\"\n  resource.change.after.cidr_blocks[_] == \"0.0.0.0/0\"\n  resource.change.after.type == \"ingress\"\n  to_number(resource.change.after.from_port) != 443\n  to_number(resource.change.after.from_port) != 80\n  msg := sprintf(\n    \"DENY: Security group rule '%s' allows 0.0.0.0/0 on port %d. Only 80 and 443 allowed from internet.\",\n    [resource.address, resource.change.after.from_port]\n  )\n}\n\n# RULE 3: Enforce encryption at rest\ndeny[msg] {\n  resource := tfplan.resource_changes[_]\n  resource.type == \"aws_db_instance\"\n  not resource.change.after.storage_encrypted\n  msg := sprintf(\n    \"DENY: RDS instance '%s' does not have encryption at rest enabled.\",\n    [resource.address]\n  )\n}\n\n# RULE 4: Enforce minimum instance size for production\ndeny[msg] {\n  resource := tfplan.resource_changes[_]\n  resource.type == \"aws_instance\"\n  instance_type := resource.change.after.instance_type\n  contains(instance_type, \"t2.micro\")\n  msg := sprintf(\n    \"DENY: Instance '%s' uses t2.micro which is not allowed in production.\",\n    [resource.address]\n  )\n}\n\n# RULE 5: Deny unencrypted EBS volumes\ndeny[msg] {\n  resource := tfplan.resource_changes[_]\n  resource.type == \"aws_ebs_volume\"\n  not resource.change.after.encrypted\n  msg := sprintf(\n    \"DENY: EBS volume '%s' is not encrypted.\",\n    [resource.address]\n  )\n}\n\n# WARN rules (advisory, don't block)\nwarn[msg] {\n  resource := tfplan.resource_changes[_]\n  resource.type == \"aws_instance\"\n  not resource.change.after.monitoring\n  msg := sprintf(\n    \"WARN: Instance '%s' does not have detailed monitoring enabled.\",\n    [resource.address]\n  )\n}\n\n# ---------- Running OPA against Terraform plan ----------\n#\n# Step 1: Generate plan JSON\n#   terraform plan -out=plan.tfplan\n#   terraform show -json plan.tfplan > plan.json\n#\n# Step 2: Evaluate with conftest\n#   conftest test plan.json --policy policy/\n#\n# Step 3: Or evaluate with OPA directly\n#   opa eval --data policy/terraform.rego \\\n#     --input plan.json \\\n#     \"data.terraform.deny\"\n#\n# Output example:\n#   FAIL - policy/terraform.rego - DENY: S3 bucket 'aws_s3_bucket.data'\n#          has public-read ACL. All buckets must be private.\nTFEOF",
      "description": "Write OPA/Rego policies to enforce security and compliance rules against Terraform plan output.",
      "explanation": "OPA (Open Policy Agent) with the Rego language provides policy-as-code for Terraform. By evaluating the plan JSON against Rego rules, you can block non-compliant changes before they reach production. Deny rules are hard blocks (must fix before apply), while warn rules are advisory. Common policies include preventing public S3 buckets, restricting security group ingress, enforcing encryption, and banning undersized instances. The conftest tool simplifies running these checks in CI pipelines.",
      "what_it_does": "Displays OPA/Rego policy definitions with five deny rules (public S3, permissive security groups, unencrypted RDS, t2.micro in production, unencrypted EBS) and one warn rule (missing detailed monitoring), plus instructions for running conftest and OPA against terraform plan JSON.",
      "next_step": "Next we will enforce mandatory tagging policies across all resources.",
      "cleanup": false
    },
    {
      "name": "Step 5: Enforce Mandatory Tagging Policies",
      "command": "cat << 'TFEOF'\n# =============================================================\n# MANDATORY TAGGING ENFORCEMENT\n# =============================================================\n# Tags are critical for cost allocation, ownership tracking,\n# compliance auditing, and automation. Enforce them at the\n# Terraform level and the AWS level.\n\n# ---------- policy/tags.rego ----------\n\npackage terraform.tags\n\nimport input as tfplan\n\n# Define required tags\nrequired_tags := {\n  \"Environment\",\n  \"Project\",\n  \"Owner\",\n  \"CostCenter\",\n  \"ManagedBy\"\n}\n\n# Taggable resource types\ntaggable_types := {\n  \"aws_instance\",\n  \"aws_s3_bucket\",\n  \"aws_db_instance\",\n  \"aws_vpc\",\n  \"aws_subnet\",\n  \"aws_security_group\",\n  \"aws_lb\",\n  \"aws_ecs_cluster\",\n  \"aws_eks_cluster\",\n  \"aws_lambda_function\",\n  \"aws_ebs_volume\",\n  \"aws_rds_cluster\"\n}\n\n# Check that all taggable resources have required tags\ndeny[msg] {\n  resource := tfplan.resource_changes[_]\n  taggable_types[resource.type]\n  resource.change.actions[_] != \"delete\"\n  tags := object.get(resource.change.after, \"tags\", {})\n  required := required_tags - {key | tags[key]}\n  count(required) > 0\n  msg := sprintf(\n    \"DENY: Resource '%s' (%s) is missing required tags: %v\",\n    [resource.address, resource.type, required]\n  )\n}\n\n# Enforce tag value patterns\ndeny[msg] {\n  resource := tfplan.resource_changes[_]\n  taggable_types[resource.type]\n  resource.change.actions[_] != \"delete\"\n  tags := object.get(resource.change.after, \"tags\", {})\n  tags.Environment\n  not re_match(\"^(production|staging|development|sandbox)$\", tags.Environment)\n  msg := sprintf(\n    \"DENY: Resource '%s' has invalid Environment tag '%s'. Must be: production, staging, development, or sandbox.\",\n    [resource.address, tags.Environment]\n  )\n}\n\n# ---------- Terraform-native tag enforcement ----------\n\n# Use default_tags in the provider (applies to ALL resources)\nprovider \"aws\" {\n  region = var.region\n\n  default_tags {\n    tags = {\n      ManagedBy   = \"terraform\"\n      Project     = var.project_name\n      Environment = var.environment\n      CostCenter  = var.cost_center\n      Owner       = var.team_owner\n    }\n  }\n}\n\n# Use a validation block in variables\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n\n  validation {\n    condition     = contains([\"production\", \"staging\", \"development\", \"sandbox\"], var.environment)\n    error_message = \"Environment must be one of: production, staging, development, sandbox.\"\n  }\n}\n\n# ---------- AWS-level enforcement with SCP ----------\n# Service Control Policy to deny untagged resource creation:\n#\n# {\n#   \"Version\": \"2012-10-17\",\n#   \"Statement\": [{\n#     \"Sid\": \"DenyUntaggedResources\",\n#     \"Effect\": \"Deny\",\n#     \"Action\": [\"ec2:RunInstances\", \"s3:CreateBucket\"],\n#     \"Resource\": \"*\",\n#     \"Condition\": {\n#       \"Null\": {\n#         \"aws:RequestTag/Environment\": \"true\",\n#         \"aws:RequestTag/Owner\": \"true\"\n#       }\n#     }\n#   }]\n# }\n#\n# THREE LAYERS OF TAG ENFORCEMENT:\n# 1. Rego policy  -> blocks non-compliant plans in CI\n# 2. default_tags -> applies tags automatically\n# 3. AWS SCP      -> blocks untagged API calls at AWS level\nTFEOF",
      "description": "Implement mandatory tagging enforcement at the Rego policy level, Terraform provider level, and AWS SCP level.",
      "explanation": "Tagging enforcement works best as a defense-in-depth strategy across three layers. First, OPA/Rego policies in CI block any Terraform plan that creates taggable resources without required tags. Second, Terraform's default_tags on the provider automatically applies baseline tags to every resource, reducing the chance of forgetting them. Third, AWS Service Control Policies (SCPs) at the organization level act as a final safety net, denying API calls that create resources without mandatory tags. The tag value validation rule ensures consistency (no typos like 'prod' vs 'production').",
      "what_it_does": "Displays Rego policies for tag enforcement (checking required tags and tag value patterns), Terraform provider default_tags configuration, variable validation for environment names, and an AWS Service Control Policy example for organization-level tag enforcement.",
      "next_step": "Next we will create an automated drift remediation workflow.",
      "cleanup": false
    },
    {
      "name": "Step 6: Create Automated Drift Remediation Workflow",
      "command": "cat << 'TFEOF'\n# =============================================================\n# AUTOMATED DRIFT REMEDIATION WORKFLOW\n# =============================================================\n# Detect drift on a schedule, categorize it, and either\n# auto-remediate low-risk drift or create tickets for review.\n\n# ---------- remediate-drift.sh ----------\n\n#!/bin/bash\nset -euo pipefail\n\nTIMESTAMP=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\nLOG_FILE=\"/var/log/drift-remediation-${TIMESTAMP}.log\"\nAUTO_FIX_TYPES=(\"tags\" \"description\" \"monitoring\")\n\nlog() { echo \"[${TIMESTAMP}] $1\" | tee -a \"$LOG_FILE\"; }\n\nlog \"Starting drift remediation workflow...\"\n\n# Step 1: Refresh state to detect real drift (not stale state)\nlog \"Refreshing Terraform state...\"\nterraform refresh -no-color >> \"$LOG_FILE\" 2>&1\n\n# Step 2: Generate plan and check for drift\nterraform plan -detailed-exitcode -out=plan.tfplan -no-color >> \"$LOG_FILE\" 2>&1\nEXIT_CODE=$?\n\nif [ $EXIT_CODE -eq 0 ]; then\n  log \"No drift detected. Exiting.\"\n  exit 0\nfi\n\nif [ $EXIT_CODE -eq 1 ]; then\n  log \"ERROR: Plan failed. Manual investigation required.\"\n  exit 1\nfi\n\n# Step 3: Categorize drift\nlog \"Drift detected. Categorizing changes...\"\nterraform show -json plan.tfplan > plan.json\n\n# Extract drifted resources\nDRIFTED=$(jq -r '.resource_changes[]? |\n  select(.change.actions != [\"no-op\"]) |\n  .address' plan.json)\n\nlog \"Drifted resources:\\n${DRIFTED}\"\n\n# Step 4: Determine remediation strategy\nfor resource in $DRIFTED; do\n  CHANGE_TYPE=$(jq -r --arg addr \"$resource\" \\\n    '.resource_changes[]? | select(.address == $addr) |\n    .change.actions | join(\",\")' plan.json)\n\n  # Check if this is a safe auto-fix\n  IS_TAG_ONLY=$(jq -r --arg addr \"$resource\" \\\n    '.resource_changes[]? | select(.address == $addr) |\n    [.change.before, .change.after] |\n    if (.[0] | del(.tags, .tags_all)) == (.[1] | del(.tags, .tags_all))\n    then \"true\" else \"false\" end' plan.json)\n\n  if [ \"$IS_TAG_ONLY\" = \"true\" ]; then\n    log \"AUTO-FIX: ${resource} (tag-only drift)\"\n    terraform apply -target=\"${resource}\" -auto-approve -no-color \\\n      >> \"$LOG_FILE\" 2>&1\n  else\n    log \"MANUAL: ${resource} (${CHANGE_TYPE}) - creating ticket\"\n    # Create Jira ticket for manual review\n    curl -s -X POST \"${JIRA_API_URL}/issue\" \\\n      -H \"Authorization: Bearer ${JIRA_TOKEN}\" \\\n      -H \"Content-Type: application/json\" \\\n      -d '{\n        \"fields\": {\n          \"project\": {\"key\": \"OPS\"},\n          \"issuetype\": {\"name\": \"Bug\"},\n          \"summary\": \"Drift detected: '\"${resource}\"'\",\n          \"description\": \"Action: '\"${CHANGE_TYPE}\"'\\nTimestamp: '\"${TIMESTAMP}\"'\",\n          \"priority\": {\"name\": \"High\"}\n        }\n      }'\n  fi\ndone\n\nlog \"Remediation workflow complete.\"\n\n# REMEDIATION STRATEGY:\n#\n#   Auto-fix (no approval needed):\n#   - Tag drift (missing or changed tags)\n#   - Description changes\n#   - Monitoring flag changes\n#\n#   Manual review (create ticket):\n#   - Security group rule changes\n#   - IAM policy changes\n#   - Network configuration changes\n#   - Instance type changes\n#   - Any destructive changes (delete/replace)\nTFEOF",
      "description": "Build an automated drift remediation workflow that auto-fixes safe drift and creates tickets for changes requiring review.",
      "explanation": "Automated remediation speeds up drift resolution for low-risk changes while maintaining human oversight for high-risk ones. The workflow first refreshes state to ensure accuracy, generates a plan, and categorizes each drifted resource. Tag-only drift is auto-fixed with targeted terraform apply. Changes to security groups, IAM, or networking create Jira tickets for manual review. This approach balances speed (auto-fixing tags in seconds) with safety (human review for security changes).",
      "what_it_does": "Displays a complete drift remediation script that refreshes state, detects drift via terraform plan, categorizes each change as auto-fixable or manual-review, applies targeted fixes for tag drift automatically, creates Jira tickets for security-sensitive drift, and logs all actions.",
      "next_step": "Next we will integrate compliance checks into a CI pipeline.",
      "cleanup": false
    },
    {
      "name": "Step 7: Integrate Compliance into CI Pipeline",
      "command": "cat << 'TFEOF'\n# =============================================================\n# CI PIPELINE COMPLIANCE INTEGRATION\n# =============================================================\n# Every Terraform change goes through a compliance gate in CI.\n# The pipeline runs OPA policies, drift checks, and cost\n# estimation before allowing terraform apply.\n\n# ---------- .github/workflows/terraform-compliance.yml ----------\n\nname: Terraform Compliance Pipeline\n\non:\n  pull_request:\n    paths: ['terraform/**']\n  schedule:\n    - cron: '0 */6 * * *'   # Drift check every 6 hours\n\nenv:\n  TF_VERSION: '1.6.0'\n  OPA_VERSION: '0.58.0'\n\njobs:\n  compliance:\n    name: Compliance Check\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TF_VERSION }}\n\n      - name: Terraform Init\n        run: terraform init -backend-config=backend.hcl\n        working-directory: terraform/\n\n      - name: Terraform Validate\n        run: terraform validate\n        working-directory: terraform/\n\n      - name: Terraform Plan\n        id: plan\n        run: |\n          terraform plan -out=plan.tfplan -detailed-exitcode \\\n            -no-color 2>&1 | tee plan-output.txt\n          echo \"exitcode=${PIPESTATUS[0]}\" >> $GITHUB_OUTPUT\n        working-directory: terraform/\n        continue-on-error: true\n\n      - name: Convert Plan to JSON\n        if: steps.plan.outputs.exitcode == '2'\n        run: terraform show -json plan.tfplan > plan.json\n        working-directory: terraform/\n\n      - name: Run OPA Policy Checks\n        if: steps.plan.outputs.exitcode == '2'\n        run: |\n          # Install conftest\n          wget -q \"https://github.com/open-policy-agent/conftest/releases/download/v0.46.0/conftest_0.46.0_Linux_x86_64.tar.gz\"\n          tar xzf conftest_*.tar.gz\n          chmod +x conftest\n\n          # Run policy checks\n          ./conftest test plan.json \\\n            --policy policy/ \\\n            --output json > compliance-results.json\n\n          # Fail if any deny rules triggered\n          DENY_COUNT=$(jq '[.[] | .failures // [] | length] | add' compliance-results.json)\n          if [ \"$DENY_COUNT\" -gt 0 ]; then\n            echo \"::error::$DENY_COUNT compliance violations found\"\n            jq -r '.[].failures[]?.msg' compliance-results.json\n            exit 1\n          fi\n        working-directory: terraform/\n\n      - name: Cost Estimation\n        if: steps.plan.outputs.exitcode == '2'\n        run: |\n          # Install infracost\n          curl -fsSL https://raw.githubusercontent.com/infracost/infracost/master/scripts/install.sh | sh\n          infracost breakdown --path plan.json \\\n            --format json > cost-estimate.json\n\n          MONTHLY_COST=$(jq -r '.totalMonthlyCost' cost-estimate.json)\n          echo \"Estimated monthly cost: \\$${MONTHLY_COST}\"\n\n          # Fail if cost exceeds threshold\n          if (( $(echo \"$MONTHLY_COST > 10000\" | bc -l) )); then\n            echo \"::error::Monthly cost \\$${MONTHLY_COST} exceeds \\$10,000 threshold\"\n            exit 1\n          fi\n        working-directory: terraform/\n\n      - name: Post PR Comment\n        if: github.event_name == 'pull_request'\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const fs = require('fs');\n            const plan = fs.readFileSync('terraform/plan-output.txt', 'utf8');\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: '## Terraform Plan\\n```\\n' + plan.slice(0, 60000) + '\\n```'\n            });\n\n  drift-check:\n    name: Scheduled Drift Detection\n    if: github.event_name == 'schedule'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Run Drift Detection\n        run: ./scripts/drift-check.sh\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}\n\n# PIPELINE GATES:\n#   1. terraform validate  -> syntax and provider checks\n#   2. terraform plan      -> preview changes\n#   3. OPA/conftest        -> compliance policy checks\n#   4. infracost           -> cost estimation threshold\n#   5. PR comment          -> human review of plan\n#   6. terraform apply     -> only after all gates pass\nTFEOF",
      "description": "Configure a GitHub Actions CI pipeline with compliance gates including OPA policies, cost estimation, and scheduled drift detection.",
      "explanation": "A compliance-integrated CI pipeline ensures every Terraform change passes policy checks before reaching production. The pipeline has five gates: validation, planning, OPA policy evaluation (blocking on deny rules), cost estimation (blocking if monthly cost exceeds a threshold), and human review via PR comments. The scheduled drift detection job runs every 6 hours independently of PRs, alerting the team via Slack when infrastructure drifts. This creates a complete governance loop: prevent non-compliant changes and detect unauthorized modifications.",
      "what_it_does": "Displays a complete GitHub Actions workflow with two jobs: a compliance check (terraform validate, plan, OPA/conftest policy evaluation, infracost cost estimation, and PR commenting) triggered on pull requests, and a scheduled drift detection job that runs every 6 hours and sends Slack notifications.",
      "next_step": "Next we will review the complete compliance framework and how all pieces fit together.",
      "cleanup": false
    },
    {
      "name": "Step 8: Review Complete Compliance Framework",
      "command": "echo '============================================================='\necho ' COMPLETE DRIFT DETECTION AND COMPLIANCE FRAMEWORK'\necho '============================================================='\necho ''\necho '--- FRAMEWORK COMPONENTS ---'\necho ''\necho '  1. DRIFT DETECTION (Reactive)'\necho '     - terraform plan -detailed-exitcode on schedule'\necho '     - JSON drift reports with categorization'\necho '     - Slack/SNS notifications on drift'\necho '     - Runs every 6 hours via GitHub Actions cron'\necho ''\necho '  2. COMPLIANCE POLICIES (Preventive)'\necho '     - OPA/Rego deny rules block non-compliant changes'\necho '     - Tag enforcement (required tags + value patterns)'\necho '     - Security rules (no public S3, restrict SG ingress)'\necho '     - Encryption enforcement (RDS, EBS, S3)'\necho ''\necho '  3. AUTOMATED REMEDIATION (Corrective)'\necho '     - Auto-fix tag drift (targeted apply)'\necho '     - Jira tickets for security-sensitive drift'\necho '     - Severity-based SLA matrix'\necho ''\necho '  4. CI PIPELINE GATES (Preventive)'\necho '     - terraform validate -> syntax check'\necho '     - terraform plan -> preview changes'\necho '     - conftest -> policy compliance'\necho '     - infracost -> cost threshold'\necho '     - PR review -> human approval'\necho ''\necho '  5. AWS-LEVEL CONTROLS (Preventive)'\necho '     - Service Control Policies for tag enforcement'\necho '     - AWS Config Rules for continuous compliance'\necho '     - CloudTrail for audit logging'\necho ''\necho '--- MATURITY MODEL ---'\necho ''\necho '  Level 1: Manual (terraform plan when someone remembers)'\necho '  Level 2: Scheduled (cron drift checks with alerts)'\necho '  Level 3: Policy-gated (OPA checks in CI pipeline)'\necho '  Level 4: Auto-remediated (safe drift fixed automatically)'\necho '  Level 5: Preventive (SCP + Config Rules block drift)'\necho ''\necho '--- METRICS TO TRACK ---'\necho ''\necho '  - Mean Time to Detect Drift (MTTD)'\necho '  - Mean Time to Remediate (MTTR)'\necho '  - Drift frequency per environment'\necho '  - Compliance policy violation rate'\necho '  - Percentage of resources with complete tags'\necho '  - Cost variance (actual vs estimated)'\necho ''\necho '============================================================='",
      "description": "Review the complete compliance framework with all components, the maturity model, and key metrics to track.",
      "explanation": "A mature compliance framework combines reactive detection (scheduled drift checks), preventive controls (OPA policies and CI gates), corrective automation (auto-remediation), and organizational controls (AWS SCPs). The maturity model provides a roadmap from ad-hoc manual checks to fully automated prevention. Tracking metrics like MTTD, MTTR, and drift frequency helps measure improvement over time and justify investment in compliance tooling.",
      "what_it_does": "Displays a summary of all five framework components (drift detection, compliance policies, automated remediation, CI pipeline gates, AWS-level controls), a five-level maturity model for compliance practices, and key metrics to measure effectiveness.",
      "next_step": "Proceed to cleanup to finish the scenario.",
      "cleanup": false
    },
    {
      "name": "Step 9: Cleanup",
      "command": "echo '=== Cleanup: Drift Detection and Compliance Scenario ===' && echo '' && echo 'This scenario focused on policies and scripts rather than' && echo 'deployed infrastructure. Clean up any local files:' && echo '' && echo '  # Remove generated plan files' && echo '  rm -f plan.tfplan plan.json plan-output.txt' && echo '  rm -f drift-report-*.json' && echo '  rm -f compliance-results.json cost-estimate.json' && echo '' && echo '  # If you deployed test infrastructure:' && echo '  terraform destroy -auto-approve' && echo '' && echo '  # Remove OPA/conftest binaries if downloaded locally' && echo '  rm -f conftest opa' && echo '' && echo 'Scenario complete! You have learned:' && echo '  - Infrastructure drift detection with terraform plan' && echo '  - Drift categorization by severity' && echo '  - OPA/Rego policy-as-code for compliance' && echo '  - Mandatory tagging enforcement at three layers' && echo '  - Automated drift remediation workflows' && echo '  - CI pipeline compliance integration' && echo '  - Compliance maturity model and metrics' && echo ''",
      "description": "Clean up all resources and files created during this scenario.",
      "explanation": "This scenario primarily produced policy files, scripts, and plan artifacts rather than deployed cloud infrastructure. Cleanup involves removing generated plan files, drift reports, and any downloaded OPA/conftest binaries. If test infrastructure was deployed to validate the policies, run terraform destroy to remove it.",
      "what_it_does": "Displays cleanup commands for removing generated plan files, drift reports, compliance results, and test binaries, then summarizes all concepts learned in this scenario.",
      "next_step": "Scenario complete. Consider exploring the disaster recovery rebuild scenario next.",
      "cleanup": true
    }
  ]
}
