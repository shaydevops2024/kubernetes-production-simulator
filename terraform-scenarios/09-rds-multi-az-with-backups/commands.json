{
  "scenario_id": "09-rds-multi-az-with-backups",
  "difficulty": "medium",
  "duration": "25 min",
  "commands": [
    {
      "name": "Step 1: Create DB Subnet Group",
      "command": "cat << 'TERRAFORM'\n# --- DB Subnet Group ---\n# RDS requires a subnet group that spans at least 2 AZs for Multi-AZ deployments.\n# This tells AWS which subnets the database instances can be placed in.\n\nresource \"aws_db_subnet_group\" \"main\" {\n  name       = \"${var.project}-${var.environment}-db-subnet-group\"\n  subnet_ids = var.private_subnet_ids   # Always use PRIVATE subnets for databases\n\n  tags = {\n    Name        = \"${var.project}-${var.environment}-db-subnet-group\"\n    Environment = var.environment\n    ManagedBy   = \"terraform\"\n  }\n}\n\n# Variables needed:\nvariable \"private_subnet_ids\" {\n  description = \"List of private subnet IDs across multiple AZs\"\n  type        = list(string)\n  # Example: [\"subnet-abc123\", \"subnet-def456\", \"subnet-ghi789\"]\n}\n\nvariable \"project\" {\n  description = \"Project name for resource naming\"\n  type        = string\n  default     = \"myapp\"\n}\n\nvariable \"environment\" {\n  description = \"Environment (dev, staging, prod)\"\n  type        = string\n  default     = \"prod\"\n}\nTERRAFORM",
      "description": "Define a DB subnet group spanning multiple availability zones",
      "explanation": "An RDS DB subnet group tells AWS which VPC subnets to place your database instances in. For Multi-AZ, you need subnets in at least 2 different availability zones. Always use private subnets so your database is never directly exposed to the internet.",
      "what_it_does": "Creates an aws_db_subnet_group resource that references your private subnets. This is a prerequisite for any RDS instance in a VPC.",
      "next_step": "Next we will create a custom parameter group to tune database settings.",
      "cleanup": false
    },
    {
      "name": "Step 2: Create Parameter Group",
      "command": "cat << 'TERRAFORM'\n# --- Custom DB Parameter Group ---\n# Parameter groups let you tune database engine settings without modifying\n# the instance directly. Changes to some parameters require a reboot.\n\nresource \"aws_db_parameter_group\" \"main\" {\n  family = \"postgres15\"   # Must match your engine + major version\n  name   = \"${var.project}-${var.environment}-pg-params\"\n\n  # --- Performance Tuning ---\n  parameter {\n    name  = \"shared_buffers\"\n    value = \"{DBInstanceClassMemory/4}\"   # 25% of instance memory\n  }\n\n  parameter {\n    name  = \"effective_cache_size\"\n    value = \"{DBInstanceClassMemory*3/4}\"  # 75% of instance memory\n  }\n\n  parameter {\n    name  = \"work_mem\"\n    value = \"65536\"   # 64MB - for complex sorts/joins\n  }\n\n  # --- Logging ---\n  parameter {\n    name  = \"log_min_duration_statement\"\n    value = \"1000\"    # Log queries slower than 1 second\n  }\n\n  parameter {\n    name  = \"log_connections\"\n    value = \"1\"\n  }\n\n  parameter {\n    name  = \"log_disconnections\"\n    value = \"1\"\n  }\n\n  # --- Connection Management ---\n  parameter {\n    name  = \"max_connections\"\n    value = \"200\"     # Adjust based on instance size\n    apply_method = \"pending-reboot\"   # Requires reboot to take effect\n  }\n\n  tags = {\n    Name        = \"${var.project}-${var.environment}-pg-params\"\n    Environment = var.environment\n    ManagedBy   = \"terraform\"\n  }\n\n  lifecycle {\n    create_before_destroy = true   # Avoid downtime during parameter changes\n  }\n}\n\n# KEY CONCEPT: apply_method can be \"immediate\" or \"pending-reboot\".\n# Static parameters (like max_connections) require pending-reboot.\n# Dynamic parameters can use immediate.\nTERRAFORM",
      "description": "Create a custom DB parameter group with production-tuned settings",
      "explanation": "Parameter groups are like configuration files for your database engine. Instead of SSHing into the DB and editing postgresql.conf, you declare settings in Terraform. The family must match your engine version (e.g., postgres15). Some parameters require a reboot to apply, which you should plan during maintenance windows.",
      "what_it_does": "Creates a custom parameter group with tuned settings for shared_buffers, effective_cache_size, slow query logging, and connection limits.",
      "next_step": "Next we will create the main RDS instance with Multi-AZ enabled.",
      "cleanup": false
    },
    {
      "name": "Step 3: Configure RDS Instance with Multi-AZ",
      "command": "cat << 'TERRAFORM'\n# --- RDS Primary Instance with Multi-AZ ---\n# Multi-AZ creates a synchronous standby replica in another AZ.\n# AWS automatically fails over to the standby if the primary fails.\n\nresource \"aws_db_instance\" \"main\" {\n  identifier = \"${var.project}-${var.environment}-postgres\"\n\n  # --- Engine Configuration ---\n  engine               = \"postgres\"\n  engine_version       = \"15.4\"\n  instance_class       = var.db_instance_class\n  parameter_group_name = aws_db_parameter_group.main.name\n\n  # --- Storage ---\n  allocated_storage     = 100        # Initial size in GB\n  max_allocated_storage = 500        # Enable storage autoscaling up to 500GB\n  storage_type          = \"gp3\"      # General Purpose SSD (gp3 is newer than gp2)\n  storage_encrypted     = true       # Always encrypt at rest\n  kms_key_id            = var.kms_key_arn   # Use custom KMS key\n\n  # --- Network ---\n  db_subnet_group_name   = aws_db_subnet_group.main.name\n  vpc_security_group_ids = [aws_security_group.rds.id]\n  publicly_accessible    = false     # NEVER make production DBs public\n  port                   = 5432\n\n  # --- High Availability ---\n  multi_az = true   # Creates synchronous standby in another AZ\n\n  # --- Credentials ---\n  db_name  = var.db_name\n  username = var.db_username\n  # Password managed via SSM (see next step)\n  manage_master_user_password = true   # AWS manages and rotates the password\n\n  # --- Maintenance ---\n  auto_minor_version_upgrade = true\n  maintenance_window         = \"sun:03:00-sun:04:00\"   # UTC\n\n  # --- Deletion Protection ---\n  deletion_protection      = var.environment == \"prod\" ? true : false\n  skip_final_snapshot      = var.environment == \"prod\" ? false : true\n  final_snapshot_identifier = var.environment == \"prod\" ? \"${var.project}-final-snapshot\" : null\n\n  tags = {\n    Name        = \"${var.project}-${var.environment}-postgres\"\n    Environment = var.environment\n    ManagedBy   = \"terraform\"\n  }\n}\n\nvariable \"db_instance_class\" {\n  description = \"RDS instance type\"\n  type        = string\n  default     = \"db.r6g.large\"   # Graviton-based for cost efficiency\n}\n\nvariable \"db_name\" {\n  type    = string\n  default = \"appdb\"\n}\n\nvariable \"db_username\" {\n  type    = string\n  default = \"app_admin\"\n}\n\n# PRODUCTION TIPS:\n# - multi_az = true doubles cost but provides automatic failover\n# - gp3 storage is cheaper than gp2 and allows independent IOPS tuning\n# - manage_master_user_password lets AWS handle password rotation via Secrets Manager\n# - deletion_protection prevents accidental terraform destroy\nTERRAFORM",
      "description": "Deploy the primary RDS instance with Multi-AZ high availability",
      "explanation": "Multi-AZ deployment creates a synchronous standby replica in a different availability zone. If the primary instance fails (hardware issue, AZ outage, etc.), AWS automatically promotes the standby within 60-120 seconds. The failover is transparent to your application since it uses the same DNS endpoint. This doubles your cost but is essential for production workloads.",
      "what_it_does": "Creates an RDS PostgreSQL instance with Multi-AZ enabled, encrypted storage with autoscaling, custom parameter group, and production safety features like deletion protection.",
      "next_step": "Next we will configure automated backups with retention and maintenance windows.",
      "cleanup": false
    },
    {
      "name": "Step 4: Set Backup Retention and Window",
      "command": "cat << 'TERRAFORM'\n# --- Backup Configuration ---\n# These settings are part of the aws_db_instance resource.\n# Shown separately here for clarity.\n\n# Add these to the aws_db_instance \"main\" resource:\n\n  # --- Automated Backups ---\n  backup_retention_period = 30          # Keep backups for 30 days (max: 35)\n  backup_window           = \"02:00-03:00\"  # UTC - must not overlap maintenance_window\n  copy_tags_to_snapshot   = true        # Snapshots inherit instance tags\n\n  # --- Performance Insights (monitoring) ---\n  performance_insights_enabled    = true\n  performance_insights_kms_key_id = var.kms_key_arn\n  performance_insights_retention_period = 731   # 2 years (free tier: 7 days)\n\n  # --- Enhanced Monitoring ---\n  monitoring_interval = 60   # Seconds (0 to disable, 1/5/10/15/30/60)\n  monitoring_role_arn = aws_iam_role.rds_monitoring.arn\n\n  # --- CloudWatch Logs ---\n  enabled_cloudwatch_logs_exports = [\n    \"postgresql\",\n    \"upgrade\"\n  ]\n\n# --- IAM Role for Enhanced Monitoring ---\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name = \"${var.project}-${var.environment}-rds-monitoring\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Principal = {\n        Service = \"monitoring.rds.amazonaws.com\"\n      }\n    }]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n\n# BACKUP STRATEGY:\n# - Automated snapshots: Daily, retained for backup_retention_period days\n# - Point-in-time recovery: Restore to any second within retention period\n# - Manual snapshots: Use aws_db_snapshot resource for pre-migration backups\n# - Cross-region: Use aws_db_instance_automated_backups_replication for DR\nTERRAFORM\n\necho \"\"\necho \"=== Backup Schedule Summary ===\"\necho \"Backup window:      02:00 - 03:00 UTC daily\"\necho \"Maintenance window: 03:00 - 04:00 UTC Sunday\"\necho \"Retention:          30 days\"\necho \"Point-in-time:      Any second within 30-day window\"\necho \"Monitoring:         Enhanced (60s) + Performance Insights (2yr)\"",
      "description": "Configure automated backups, monitoring, and maintenance windows",
      "explanation": "RDS automated backups take daily snapshots and capture transaction logs continuously, enabling point-in-time recovery to any second within your retention period (up to 35 days). The backup window should not overlap with the maintenance window. Enhanced Monitoring provides OS-level metrics at up to 1-second granularity, while Performance Insights helps identify query bottlenecks.",
      "what_it_does": "Configures a 30-day backup retention, daily backup window, Performance Insights for query analysis, Enhanced Monitoring for OS metrics, and CloudWatch log exports.",
      "next_step": "Next we will store the database password securely in SSM Parameter Store.",
      "cleanup": false
    },
    {
      "name": "Step 5: Store Password in SSM Parameter Store",
      "command": "cat << 'TERRAFORM'\n# --- Secure Password Management ---\n# Option A: Generate random password and store in SSM\n# Option B: Use manage_master_user_password (AWS-managed, recommended)\n# Here we show Option A for learning, but Option B is preferred in production.\n\n# --- Option A: Self-managed password ---\nresource \"random_password\" \"db_master\" {\n  length           = 32\n  special          = true\n  override_special = \"!#$%^&*()-_=+[]{}|:,.<>?\"\n}\n\n# Store in SSM Parameter Store (SecureString - encrypted at rest)\nresource \"aws_ssm_parameter\" \"db_password\" {\n  name        = \"/${var.project}/${var.environment}/database/master-password\"\n  description = \"RDS master password for ${var.project}-${var.environment}\"\n  type        = \"SecureString\"\n  value       = random_password.db_master.result\n  key_id      = var.kms_key_arn   # Custom KMS key for encryption\n\n  tags = {\n    Environment = var.environment\n    ManagedBy   = \"terraform\"\n  }\n}\n\n# Store connection string for applications\nresource \"aws_ssm_parameter\" \"db_connection_string\" {\n  name        = \"/${var.project}/${var.environment}/database/connection-string\"\n  description = \"Full database connection string\"\n  type        = \"SecureString\"\n  value       = \"postgresql://${var.db_username}:${random_password.db_master.result}@${aws_db_instance.main.endpoint}/${var.db_name}\"\n  key_id      = var.kms_key_arn\n\n  tags = {\n    Environment = var.environment\n    ManagedBy   = \"terraform\"\n  }\n}\n\n# Store individual connection parameters (useful for apps that need them separate)\nresource \"aws_ssm_parameter\" \"db_host\" {\n  name  = \"/${var.project}/${var.environment}/database/host\"\n  type  = \"String\"   # Not secret, just the hostname\n  value = aws_db_instance.main.address\n}\n\nresource \"aws_ssm_parameter\" \"db_port\" {\n  name  = \"/${var.project}/${var.environment}/database/port\"\n  type  = \"String\"\n  value = tostring(aws_db_instance.main.port)\n}\n\n# --- Option B (Preferred): AWS-managed password ---\n# Just set manage_master_user_password = true on the RDS instance.\n# AWS stores and auto-rotates the password in Secrets Manager.\n# Retrieve it with: aws_db_instance.main.master_user_secret[0].secret_arn\n\n# IMPORTANT: Never store passwords in:\n# - terraform.tfvars (committed to git)\n# - Environment variables (visible in process listings)\n# - Hardcoded in .tf files\nTERRAFORM\n\necho \"\"\necho \"=== SSM Parameter Store Hierarchy ===\"\necho \"/myapp/prod/database/master-password  (SecureString)\"\necho \"/myapp/prod/database/connection-string (SecureString)\"\necho \"/myapp/prod/database/host              (String)\"\necho \"/myapp/prod/database/port              (String)\"",
      "description": "Store database credentials securely using SSM Parameter Store",
      "explanation": "Never hardcode database passwords in Terraform files or pass them as plain-text variables. SSM Parameter Store with SecureString type encrypts values at rest using KMS. Applications can retrieve credentials at runtime using IAM permissions, and you get audit trails via CloudTrail. For even better security, use manage_master_user_password which lets AWS handle rotation automatically.",
      "what_it_does": "Generates a random 32-character password, stores it as a SecureString in SSM Parameter Store, and also stores the full connection string and individual connection parameters for application use.",
      "next_step": "Next we will create a read replica for scaling read operations.",
      "cleanup": false
    },
    {
      "name": "Step 6: Create Read Replica",
      "command": "cat << 'TERRAFORM'\n# --- Read Replica ---\n# Read replicas use asynchronous replication from the primary.\n# They offload read traffic but may have slight replication lag.\n\nresource \"aws_db_instance\" \"read_replica\" {\n  count = var.create_read_replica ? 1 : 0\n\n  identifier          = \"${var.project}-${var.environment}-postgres-replica\"\n  replicate_source_db = aws_db_instance.main.identifier\n\n  # --- Can differ from primary ---\n  instance_class = var.replica_instance_class   # Can be smaller than primary\n\n  # --- Replica-specific settings ---\n  multi_az            = false          # Replicas usually don't need Multi-AZ\n  publicly_accessible = false\n  storage_encrypted   = true           # Inherits KMS key from primary\n\n  # --- Performance ---\n  performance_insights_enabled = true\n  monitoring_interval          = 60\n  monitoring_role_arn          = aws_iam_role.rds_monitoring.arn\n\n  # --- Note: These are inherited from primary and cannot be set ---\n  # db_name, username, password, db_subnet_group_name, parameter_group\n\n  # --- Replica does NOT need backup settings ---\n  # backup_retention_period is automatically 0 for replicas\n\n  tags = {\n    Name        = \"${var.project}-${var.environment}-postgres-replica\"\n    Environment = var.environment\n    Role        = \"read-replica\"\n    ManagedBy   = \"terraform\"\n  }\n}\n\nvariable \"create_read_replica\" {\n  description = \"Whether to create a read replica\"\n  type        = bool\n  default     = true\n}\n\nvariable \"replica_instance_class\" {\n  description = \"Instance class for read replica (can be smaller than primary)\"\n  type        = string\n  default     = \"db.r6g.large\"\n}\n\n# --- Outputs for application configuration ---\noutput \"primary_endpoint\" {\n  description = \"Primary instance endpoint (reads + writes)\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"replica_endpoint\" {\n  description = \"Read replica endpoint (reads only)\"\n  value       = var.create_read_replica ? aws_db_instance.read_replica[0].endpoint : null\n}\n\n# APPLICATION PATTERN:\n# - Writes -> primary_endpoint\n# - Reads  -> replica_endpoint (or use RDS Proxy for connection pooling)\n# - Replica lag is typically < 1 second but can spike during heavy writes\nTERRAFORM",
      "description": "Create a read replica to scale read-heavy database workloads",
      "explanation": "Read replicas use asynchronous replication, meaning there is a small delay (usually under 1 second) between writes to the primary and their appearance on the replica. They are ideal for offloading reporting queries, analytics, and read-heavy application traffic. The replica can use a different instance class than the primary, and in a disaster you can promote a replica to become a standalone primary.",
      "what_it_does": "Creates an RDS read replica that asynchronously replicates from the primary instance. The replica has its own endpoint for read traffic and can be conditionally created using a variable toggle.",
      "next_step": "Next we will review the complete database infrastructure setup.",
      "cleanup": false
    },
    {
      "name": "Step 7: Review Complete Database Setup",
      "command": "cat << 'TERRAFORM'\n# =============================================================\n# COMPLETE RDS PRODUCTION ARCHITECTURE SUMMARY\n# =============================================================\n\n# --- Security Group for RDS ---\nresource \"aws_security_group\" \"rds\" {\n  name_prefix = \"${var.project}-${var.environment}-rds-\"\n  vpc_id      = var.vpc_id\n\n  # Allow PostgreSQL from application subnets only\n  ingress {\n    description     = \"PostgreSQL from app layer\"\n    from_port       = 5432\n    to_port         = 5432\n    protocol        = \"tcp\"\n    security_groups = [var.app_security_group_id]  # Only app servers can connect\n  }\n\n  # No egress needed for RDS (AWS manages replication traffic)\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n\n  tags = {\n    Name = \"${var.project}-${var.environment}-rds-sg\"\n  }\n}\nTERRAFORM\n\necho \"\"\necho \"==========================================\"\necho \"  PRODUCTION RDS ARCHITECTURE OVERVIEW\"\necho \"==========================================\"\necho \"\"\necho \"  [App Servers] ----> [Security Group :5432]\"\necho \"        |                    |\"\necho \"        v                    v\"\necho \"  +-----------+    +------------------+\"\necho \"  | RDS Proxy |    | Primary Instance |\"\necho \"  | (optional)|    | (Multi-AZ)       |\"\necho \"  +-----------+    +--------+---------+\"\necho \"                           |\"\necho \"              +------------+------------+\"\necho \"              |                         |\"\necho \"     +--------v---------+     +---------v--------+\"\necho \"     | Standby (sync)   |     | Read Replica     |\"\necho \"     | Auto-failover    |     | (async, reads)   |\"\necho \"     +------------------+     +------------------+\"\necho \"\"\necho \"  Backups:     Daily snapshots, 30-day retention\"\necho \"  Encryption:  At rest (KMS) + In transit (SSL)\"\necho \"  Monitoring:  Enhanced Monitoring + Performance Insights\"\necho \"  Credentials: SSM Parameter Store (SecureString)\"\necho \"  Protection:  deletion_protection = true\"",
      "description": "Review the complete production RDS architecture and all components",
      "explanation": "A production RDS setup involves multiple layers: network isolation via VPC and security groups, high availability via Multi-AZ, read scaling via replicas, security via encryption and credential management, observability via monitoring and log exports, and safety via backup retention and deletion protection. Each layer addresses a different failure mode or operational need.",
      "what_it_does": "Displays the security group configuration and a visual architecture overview of the complete RDS setup including the primary instance, Multi-AZ standby, read replica, backup strategy, and monitoring.",
      "next_step": "Final step: clean up all displayed resources.",
      "cleanup": false
    },
    {
      "name": "Step 8: Cleanup",
      "command": "echo '=== Cleanup ===' && echo 'In a real environment, you would destroy these resources with:' && echo '' && echo '  terraform destroy' && echo '' && echo 'IMPORTANT: For production databases:' && echo '  1. Take a final manual snapshot before destroying' && echo '  2. Verify skip_final_snapshot = false (Terraform will create one)' && echo '  3. Download any needed data exports first' && echo '  4. Remove deletion_protection first: terraform apply -var=\"environment=dev\"' && echo '  5. Then run terraform destroy' && echo '' && echo 'Resources that would be destroyed:' && echo '  - aws_db_instance.read_replica' && echo '  - aws_db_instance.main (primary + standby)' && echo '  - aws_ssm_parameter.db_password' && echo '  - aws_ssm_parameter.db_connection_string' && echo '  - aws_ssm_parameter.db_host' && echo '  - aws_ssm_parameter.db_port' && echo '  - aws_db_parameter_group.main' && echo '  - aws_db_subnet_group.main' && echo '  - aws_security_group.rds' && echo '  - aws_iam_role.rds_monitoring' && echo '' && echo 'Scenario complete!'",
      "description": "Clean up all simulated RDS resources",
      "explanation": "Destroying a production database requires careful planning. Always ensure you have a final snapshot, verify backups are accessible, and consider that deletion protection must be removed before Terraform can destroy the instance. In a real workflow, you would also update dependent services to point to a new database if migrating.",
      "what_it_does": "Displays the cleanup steps and lists all resources that would be destroyed by terraform destroy.",
      "next_step": "",
      "cleanup": true
    }
  ]
}