{
  "scenario_id": "02-variables-locals-and-outputs",
  "difficulty": "easy",
  "duration": "15 min",
  "commands": [
    {
      "name": "Step 1: Review Variable Declarations",
      "command": "cat << 'TFEOF'\n# variables.tf - Input Variable Declarations\n# Variables make your Terraform code reusable across environments.\n\nvariable \"environment\" {\n  description = \"Deployment environment (dev, staging, prod)\"\n  type        = string\n  default     = \"dev\"\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be one of: dev, staging, prod.\"\n  }\n}\n\nvariable \"project_name\" {\n  description = \"Name of the project, used in resource naming\"\n  type        = string\n  # No default = required variable (must be provided)\n}\n\nvariable \"instance_count\" {\n  description = \"Number of EC2 instances to create\"\n  type        = number\n  default     = 2\n\n  validation {\n    condition     = var.instance_count >= 1 && var.instance_count <= 10\n    error_message = \"Instance count must be between 1 and 10.\"\n  }\n}\n\nvariable \"enable_monitoring\" {\n  description = \"Whether to enable detailed CloudWatch monitoring\"\n  type        = bool\n  default     = false\n}\n\nvariable \"allowed_cidrs\" {\n  description = \"List of CIDR blocks allowed to access the application\"\n  type        = list(string)\n  default     = [\"10.0.0.0/8\"]\n}\n\nvariable \"extra_tags\" {\n  description = \"Additional tags to apply to all resources\"\n  type        = map(string)\n  default     = {}\n}\nTFEOF",
      "description": "Examine variable declarations with types, defaults, descriptions, and validation rules",
      "explanation": "Variables are declared in variables.tf by convention. Each variable has a type constraint (string, number, bool, list, map, object), an optional default value, and a description. Variables without defaults are required -- Terraform will prompt for them or error if not provided. The validation block adds custom rules that run before any resources are created, catching misconfigurations early. In production, always add descriptions and validation to prevent misconfiguration.",
      "what_it_does": "Displays variable declarations showing six different variable types: string with validation, required string, number with range validation, boolean, list of strings, and map of strings.",
      "next_step": "Next we will explore complex variable types including objects and sensitive variables.",
      "cleanup": false
    },
    {
      "name": "Step 2: Understand Complex Variable Types",
      "command": "cat << 'TFEOF'\n# variables.tf (continued) - Complex Types\n\n# Object type with a defined structure\nvariable \"database_config\" {\n  description = \"Database configuration parameters\"\n  type = object({\n    engine         = string\n    engine_version = string\n    instance_class = string\n    storage_gb     = number\n    multi_az       = bool\n    backup_days    = number\n  })\n  default = {\n    engine         = \"postgres\"\n    engine_version = \"15.4\"\n    instance_class = \"db.t3.medium\"\n    storage_gb     = 100\n    multi_az       = false\n    backup_days    = 7\n  }\n}\n\n# Sensitive variable - value hidden in plan/apply output\nvariable \"db_password\" {\n  description = \"Database master password\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_password) >= 16\n    error_message = \"Database password must be at least 16 characters.\"\n  }\n}\n\n# Tuple type - ordered collection of different types\nvariable \"availability_zones\" {\n  description = \"AZs to deploy into\"\n  type        = list(string)\n  default     = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n}\nTFEOF\necho ''\necho '=== Variable Type Hierarchy ==='\necho ''\necho 'Primitive:  string, number, bool'\necho 'Collection: list(type), set(type), map(type)'\necho 'Structural: object({...}), tuple([...])'\necho 'Special:    any (accepts any type)'\necho ''\necho 'Pro tip: Use \"object\" for configs with known structures.'\necho '         Use \"map\" when keys are dynamic/unknown.'",
      "description": "Learn about complex variable types including objects, sensitive variables, and the type hierarchy",
      "explanation": "Object types define a strict schema -- every attribute must be provided and match its type. This is ideal for configuration blocks where the structure is known. Sensitive variables have their values redacted from terraform plan and apply output, but they are still stored in plain text in the state file. For true secrets management, integrate with HashiCorp Vault or AWS Secrets Manager. The type hierarchy helps you choose the right type: use primitives for simple values, collections for lists of the same type, and objects for structured configuration.",
      "what_it_does": "Shows complex variable types including an object type for database configuration, a sensitive variable for passwords with length validation, and the complete variable type hierarchy.",
      "next_step": "Now let's see how locals eliminate repetition in your code.",
      "cleanup": false
    },
    {
      "name": "Step 3: Create a Locals Block",
      "command": "cat << 'TFEOF'\n# locals.tf - Computed Values and DRY Configuration\n# Locals compute values from variables, reducing repetition.\n\nlocals {\n  # Naming convention: {project}-{environment}-{resource}\n  name_prefix = \"${var.project_name}-${var.environment}\"\n\n  # Common tags applied to every resource\n  common_tags = merge(\n    {\n      Project     = var.project_name\n      Environment = var.environment\n      ManagedBy   = \"terraform\"\n      CreatedAt   = timestamp()\n    },\n    var.extra_tags\n  )\n\n  # Environment-specific configurations\n  env_config = {\n    dev = {\n      instance_type = \"t3.small\"\n      min_size      = 1\n      max_size      = 2\n      multi_az      = false\n    }\n    staging = {\n      instance_type = \"t3.medium\"\n      min_size      = 2\n      max_size      = 4\n      multi_az      = true\n    }\n    prod = {\n      instance_type = \"t3.large\"\n      min_size      = 3\n      max_size      = 10\n      multi_az      = true\n    }\n  }\n\n  # Select config for current environment\n  current_config = local.env_config[var.environment]\n\n  # Computed CIDR blocks for subnets\n  public_subnets = [\n    for i, az in var.availability_zones :\n    cidrsubnet(\"10.0.0.0/16\", 8, i)\n  ]\n  private_subnets = [\n    for i, az in var.availability_zones :\n    cidrsubnet(\"10.0.0.0/16\", 8, i + 100)\n  ]\n}\nTFEOF\necho ''\necho '=== How locals are referenced ==='\necho ''\necho '  Variables:  var.environment'\necho '  Locals:     local.name_prefix'\necho '  Resources:  aws_s3_bucket.app.id'\necho '  Data:       data.aws_ami.ubuntu.id'",
      "description": "Build a locals block that computes naming conventions, merged tags, and environment-specific configs",
      "explanation": "Locals are computed values that simplify your code. Unlike variables, locals cannot be set by the user -- they are derived from variables, resource attributes, or functions. The merge() function combines maps, making it easy to add custom tags on top of standard ones. The env_config map pattern is extremely common in production -- it defines different configurations per environment and selects the right one using the environment variable. The cidrsubnet() function mathematically divides a VPC CIDR into smaller subnet CIDRs, avoiding manual calculation errors.",
      "what_it_does": "Displays a locals block with a naming prefix, merged common tags, environment-specific configuration maps, computed subnet CIDRs, and shows the reference syntax for variables vs locals vs resources.",
      "next_step": "Now let's define outputs to expose values for other modules and scripts.",
      "cleanup": false
    },
    {
      "name": "Step 4: Define Outputs",
      "command": "cat << 'TFEOF'\n# outputs.tf - Expose values for other modules and automation\n\noutput \"bucket_arn\" {\n  description = \"ARN of the S3 bucket\"\n  value       = aws_s3_bucket.app_artifacts.arn\n}\n\noutput \"bucket_domain\" {\n  description = \"Regional domain name for the S3 bucket\"\n  value       = aws_s3_bucket.app_artifacts.bucket_regional_domain_name\n}\n\n# Sensitive output - hidden in CLI output\noutput \"db_connection_string\" {\n  description = \"Database connection string\"\n  value       = \"postgresql://${var.project_name}_admin:${var.db_password}@${aws_db_instance.main.endpoint}/${var.project_name}\"\n  sensitive   = true\n}\n\n# Complex output - map of subnet IDs\noutput \"network_info\" {\n  description = \"Network configuration details\"\n  value = {\n    vpc_id          = aws_vpc.main.id\n    public_subnets  = aws_subnet.public[*].id\n    private_subnets = aws_subnet.private[*].id\n    nat_gateway_ip  = aws_eip.nat.public_ip\n  }\n}\n\n# Conditional output\noutput \"monitoring_dashboard_url\" {\n  description = \"CloudWatch dashboard URL (only in prod)\"\n  value       = var.environment == \"prod\" ? \"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#dashboards:name=${local.name_prefix}\" : null\n}\nTFEOF\necho ''\necho '=== How outputs are consumed ==='\necho ''\necho '  # CLI: View all outputs'\necho '  terraform output'\necho '  terraform output -json'\necho ''\necho '  # CLI: Get a specific output'\necho '  terraform output bucket_arn'\necho ''\necho '  # In another module: Reference via remote state'\necho '  data \"terraform_remote_state\" \"infra\" {'\necho '    backend = \"s3\"'\necho '    config  = { bucket = \"tf-state\", key = \"infra/terraform.tfstate\" }'\necho '  }'\necho '  # Usage: data.terraform_remote_state.infra.outputs.bucket_arn'",
      "description": "Define outputs to expose resource attributes for other modules, scripts, and CI/CD pipelines",
      "explanation": "Outputs serve three purposes: (1) displaying values after apply so you can see endpoints and IDs, (2) sharing data between Terraform modules via remote state, and (3) feeding values into external scripts or CI/CD pipelines via 'terraform output -json'. Sensitive outputs are hidden from terminal display but accessible programmatically. The splat expression [*].id collects a specific attribute from all instances of a resource. Conditional outputs using ternary expressions let you expose values only in certain environments.",
      "what_it_does": "Shows output declarations including simple values, sensitive database connection strings, complex map outputs for network info, and conditional outputs, plus how outputs are consumed from CLI and other modules.",
      "next_step": "Let's create a terraform.tfvars file to set variable values.",
      "cleanup": false
    },
    {
      "name": "Step 5: Create terraform.tfvars",
      "command": "cat << 'TFEOF'\n# terraform.tfvars - Default variable values for this workspace\n# This file is automatically loaded by Terraform.\n# DO NOT commit secrets to this file!\n\nproject_name     = \"k8s-simulator\"\nenvironment      = \"dev\"\ninstance_count   = 2\nenable_monitoring = false\n\nallowed_cidrs = [\n  \"10.0.0.0/8\",\n  \"172.16.0.0/12\",\n]\n\nextra_tags = {\n  Team       = \"platform-engineering\"\n  CostCenter = \"CC-1234\"\n}\n\ndatabase_config = {\n  engine         = \"postgres\"\n  engine_version = \"15.4\"\n  instance_class = \"db.t3.medium\"\n  storage_gb     = 100\n  multi_az       = false\n  backup_days    = 7\n}\n\navailability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\nTFEOF\necho ''\necho '=== Variable Precedence (lowest to highest) ==='\necho ''\necho '  1. Default values in variable blocks'\necho '  2. terraform.tfvars (auto-loaded)'\necho '  3. *.auto.tfvars files (auto-loaded, alphabetical)'\necho '  4. -var-file=prod.tfvars (CLI flag)'\necho '  5. -var=\"key=value\" (CLI flag)'\necho '  6. TF_VAR_environment (environment variable)'\necho ''\necho '=== Environment-specific pattern ==='\necho ''\necho '  environments/'\necho '  ├── dev.tfvars'\necho '  ├── staging.tfvars'\necho '  └── prod.tfvars'\necho ''\necho '  # Usage:'\necho '  terraform plan -var-file=environments/prod.tfvars'\necho '  terraform apply -var-file=environments/prod.tfvars'",
      "description": "Create a terraform.tfvars file and understand variable precedence order",
      "explanation": "terraform.tfvars is automatically loaded when Terraform runs. It provides values for your declared variables without modifying the code. The precedence order is critical to understand: environment variables (TF_VAR_*) override CLI flags, which override tfvars files, which override defaults. This allows you to set sensible defaults in terraform.tfvars, override per-environment with -var-file, and override individual values in CI/CD with -var or TF_VAR_* environment variables. Never put secrets in tfvars files committed to git -- use environment variables or a secrets manager instead.",
      "what_it_does": "Displays a terraform.tfvars file with values for all declared variables, the complete variable precedence order from lowest to highest, and the environment-specific file pattern used in production.",
      "next_step": "Let's see terraform plan with these variables in action.",
      "cleanup": false
    },
    {
      "name": "Step 6: Plan with Variables Applied",
      "command": "echo '=== terraform plan -var-file=environments/prod.tfvars ==='\necho ''\necho 'Using variable values:'\necho '  project_name     = \"k8s-simulator\"'\necho '  environment      = \"prod\"           # overridden by prod.tfvars'\necho '  instance_count   = 3                # overridden by prod.tfvars'\necho '  enable_monitoring = true             # overridden by prod.tfvars'\necho ''\necho 'Computed local values:'\necho '  name_prefix     = \"k8s-simulator-prod\"'\necho '  current_config   = {'\necho '    instance_type = \"t3.large\"'\necho '    min_size      = 3'\necho '    max_size      = 10'\necho '    multi_az      = true'\necho '  }'\necho '  public_subnets  = [\"10.0.0.0/24\", \"10.0.1.0/24\", \"10.0.2.0/24\"]'\necho '  private_subnets = [\"10.0.100.0/24\", \"10.0.101.0/24\", \"10.0.102.0/24\"]'\necho ''\necho 'Merged tags:'\necho '  {'\necho '    Project     = \"k8s-simulator\"'\necho '    Environment = \"prod\"'\necho '    ManagedBy   = \"terraform\"'\necho '    Team        = \"platform-engineering\"'\necho '    CostCenter  = \"CC-1234\"'\necho '  }'\necho ''\necho 'Plan: 15 to add, 0 to change, 0 to destroy.'\necho ''\necho '=== KEY INSIGHT ==='\necho 'Same code, different environment. The locals block selected the \"prod\"'\necho 'config automatically, giving us larger instances, higher min/max counts,'\necho 'and multi-AZ enabled. This is the power of variables + locals.'",
      "description": "Run terraform plan with a production tfvars file and observe how variables and locals interact",
      "explanation": "This demonstrates the core value proposition of variables and locals: the same Terraform code deploys different configurations per environment. The prod.tfvars overrides defaults with production-appropriate values (more instances, monitoring enabled), and the locals block automatically selects the production config map. The merged tags combine standard tags with extra_tags from the tfvars. This pattern eliminates code duplication between environments, which is one of the most common mistakes in infrastructure-as-code projects.",
      "what_it_does": "Simulates a terraform plan with production variables showing how variable values flow through locals to produce environment-specific resource configurations and merged tags.",
      "next_step": "Let's see how terraform output works after an apply.",
      "cleanup": false
    },
    {
      "name": "Step 7: Show How Outputs Work",
      "command": "echo '=== terraform output ==='\necho ''\necho 'bucket_arn = \"arn:aws:s3:::k8s-simulator-prod-artifacts\"'\necho 'bucket_domain = \"k8s-simulator-prod-artifacts.s3.us-east-1.amazonaws.com\"'\necho 'db_connection_string = <sensitive>'\necho 'monitoring_dashboard_url = \"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#dashboards:name=k8s-simulator-prod\"'\necho 'network_info = {'\necho '  \"nat_gateway_ip\" = \"54.210.123.45\"'\necho '  \"private_subnets\" = ['\necho '    \"subnet-0abc111\",'\necho '    \"subnet-0abc222\",'\necho '    \"subnet-0abc333\",'\necho '  ]'\necho '  \"public_subnets\" = ['\necho '    \"subnet-0def111\",'\necho '    \"subnet-0def222\",'\necho '    \"subnet-0def333\",'\necho '  ]'\necho '  \"vpc_id\" = \"vpc-0a1b2c3d4e\"'\necho '}'\necho ''\necho '=== terraform output -json (for scripts/CI) ==='\ncat << 'JSONEOF'\n{\n  \"bucket_arn\": {\n    \"value\": \"arn:aws:s3:::k8s-simulator-prod-artifacts\",\n    \"type\": \"string\",\n    \"sensitive\": false\n  },\n  \"db_connection_string\": {\n    \"value\": \"postgresql://k8s-simulator_admin:****@db.example.com:5432/k8s-simulator\",\n    \"type\": \"string\",\n    \"sensitive\": true\n  },\n  \"network_info\": {\n    \"value\": {\n      \"vpc_id\": \"vpc-0a1b2c3d4e\",\n      \"public_subnets\": [\"subnet-0def111\", \"subnet-0def222\", \"subnet-0def333\"],\n      \"private_subnets\": [\"subnet-0abc111\", \"subnet-0abc222\", \"subnet-0abc333\"],\n      \"nat_gateway_ip\": \"54.210.123.45\"\n    },\n    \"type\": \"object\",\n    \"sensitive\": false\n  }\n}\nJSONEOF\necho ''\necho '=== Common output patterns in CI/CD ==='\necho ''\necho '  # Pass VPC ID to next Terraform module'\necho '  export VPC_ID=$(terraform output -raw network_info | jq -r .vpc_id)'\necho ''\necho '  # Pass to kubectl'\necho '  terraform output -raw kubeconfig > ~/.kube/config'",
      "description": "See terraform output in both human-readable and JSON format for CI/CD integration",
      "explanation": "Outputs bridge the gap between Terraform and everything else in your pipeline. The human-readable format is great for quick verification. The JSON format (-json flag) is essential for CI/CD pipelines and scripts that need to parse values programmatically. Sensitive outputs show <sensitive> in the terminal but can be accessed via 'terraform output -raw db_connection_string' when needed. Complex outputs like network_info can be parsed with jq in shell scripts. In a multi-module architecture, outputs from one module become inputs to another through remote state data sources.",
      "what_it_does": "Displays terraform output in both human-readable and JSON formats, showing how sensitive values are hidden, how complex outputs are structured, and how to consume outputs in CI/CD pipelines.",
      "next_step": "Cleanup step to complete the scenario.",
      "cleanup": false
    },
    {
      "name": "Step 8: Cleanup",
      "command": "echo '=== Scenario Complete ==='\necho ''\necho 'In a real environment, you would run:'\necho '  terraform destroy -var-file=environments/prod.tfvars'\necho ''\necho 'This destroys all resources while respecting the same variable values'\necho 'that were used to create them.'\necho ''\necho '=== Summary: Variables, Locals, and Outputs ==='\necho ''\necho 'VARIABLES (Input):'\necho '  - Declared in variables.tf with type, default, description, validation'\necho '  - Set via .tfvars files, CLI flags, or TF_VAR_* env vars'\necho '  - Referenced as: var.environment'\necho ''\necho 'LOCALS (Computed):'\necho '  - Defined in locals.tf, derived from variables and resources'\necho '  - Eliminate repetition (DRY principle)'\necho '  - Referenced as: local.name_prefix'\necho ''\necho 'OUTPUTS (Exposed):'\necho '  - Defined in outputs.tf, expose values after apply'\necho '  - Used for cross-module communication and CI/CD integration'\necho '  - Referenced in other modules via terraform_remote_state'\necho ''\necho 'Best Practices:'\necho '  1. Always add descriptions and validation to variables'\necho '  2. Use locals for naming conventions and environment configs'\necho '  3. Never hardcode values that change between environments'\necho '  4. Use sensitive=true for passwords and tokens'\necho '  5. Keep terraform.tfvars out of git if it contains secrets'",
      "description": "Clean up and review what was learned about variables, locals, and outputs",
      "explanation": "This scenario covered the three pillars of Terraform data flow: variables for input, locals for computation, and outputs for exposure. Together, they enable you to write reusable, environment-agnostic infrastructure code. The key insight is that the same Terraform code can deploy to dev, staging, and production with different configurations, all controlled by variable files.",
      "what_it_does": "Summarizes the scenario with a complete reference guide for variables, locals, and outputs including their declaration files, reference syntax, and production best practices.",
      "next_step": "Try the next scenario to learn about remote state backends.",
      "cleanup": true
    }
  ]
}
