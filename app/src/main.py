# app/src/main.py - Updated for self-contained scenarios
# Key changes:
# 1. Monitors BOTH "k8s-multi-demo" and "scenarios" namespaces
# 2. Reads YAML files from scenario directories
# 3. All scenarios marked with namespace: "scenarios"
# 4. Better error handling and logging

from database import get_db, check_db_connection, get_db_stats, User, Task, init_db
from sqlalchemy.orm import Session
from fastapi import Depends, HTTPException
from fastapi import FastAPI, Response, Request
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from prometheus_client import Counter, Histogram, generate_latest
from pydantic import BaseModel
import asyncio
import os
import logging
import subprocess
from datetime import datetime, timezone
from collections import deque
from pathlib import Path
from kubernetes import client, config
from kubernetes.client.rest import ApiException
import json

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI(title="K8s Production Demo", version="2.0.0")

# Mount static files directory
static_dir = Path(__file__).parent / "static"
static_dir.mkdir(exist_ok=True)
app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")

REQUEST_COUNT = Counter('app_requests_total', 'Total app requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('app_request_duration_seconds', 'Request duration')

app_ready = True
app_healthy = True
load_test_running = False
load_test_task = None

log_buffer = deque(maxlen=100)

# Initialize Kubernetes client
try:
    config.load_incluster_config()
    k8s_apps_v1 = client.AppsV1Api()
    k8s_core_v1 = client.CoreV1Api()
    k8s_available = True
    logger.info("‚úÖ Kubernetes client initialized successfully")
except Exception as e:
    logger.error(f"‚ö†Ô∏è Failed to initialize Kubernetes client: {e}")
    k8s_apps_v1 = None
    k8s_core_v1 = None
    k8s_available = False

class LogBufferHandler(logging.Handler):
    def emit(self, record):
        log_entry = self.format(record)
        log_buffer.append({
            'timestamp': datetime.now().isoformat(),
            'level': record.levelname,
            'message': log_entry
        })

buffer_handler = LogBufferHandler()
buffer_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(buffer_handler)

APP_ENV = os.getenv('APP_ENV', 'development')
APP_NAME = os.getenv('APP_NAME', 'k8s-demo-app')
SECRET_TOKEN = os.getenv('SECRET_TOKEN', 'no-secret-configured')
CONFIGMAP_VALUE = os.getenv('CONFIGMAP_VALUE', 'no-configmap-configured')

# Cached ArgoCD server status (only check cluster state, not CLI)
_argocd_server_cache = {"server_running": None, "installed": None, "checked": False}

# In-memory storage for prerequisite check results (1-hour TTL handled implicitly)
prerequisite_reports = {}

# Prerequisites checker script - generates a bash script that checks tools on user's host
CHECKER_SCRIPT = """#!/bin/bash
# Prerequisites Checker Script
# Generated by Kubernetes Production Simulator

SESSION_ID="${1:-$(cat /proc/sys/kernel/random/uuid 2>/dev/null || uuidgen || echo "session-$(date +%s)")}"
REPORT_URL="http://localhost:30080/api/prerequisites/report"

check_tool() {
    local tool=$1
    local check_cmd=$2

    if command -v $tool &> /dev/null; then
        version=$($check_cmd 2>&1 | head -1 || echo "unknown")
        # Escape quotes and special characters for JSON
        version=$(echo "$version" | sed 's/"/\\\\"/g' | tr -d '\\n')
        echo "    \\"$tool\\": {\\"installed\\": true, \\"version\\": \\"$version\\", \\"location\\": \\"local\\"},"
    else
        echo "    \\"$tool\\": {\\"installed\\": false, \\"version\\": null, \\"location\\": null},"
    fi
}

echo "üì¶ Checking prerequisites on your local machine..."
echo ""

# Build JSON report
JSON_TOOLS=$(cat <<EOF
$(check_tool "docker" "docker --version")
$(check_tool "kubectl" "kubectl version --client")
$(check_tool "kind" "kind version")
$(check_tool "helm" "helm version")
$(check_tool "terraform" "terraform version")
$(check_tool "ansible" "ansible --version")
$(check_tool "gitlab-runner" "gitlab-runner --version")
EOF
)

# Remove trailing comma from last entry
JSON_TOOLS=$(echo "$JSON_TOOLS" | sed '$ s/,$//')

JSON=$(cat <<EOF
{
  "session_id": "$SESSION_ID",
  "tools": {
$JSON_TOOLS
  }
}
EOF
)

# Send report to web app
echo "üì§ Sending results to web app..."
RESPONSE=$(curl -X POST -H "Content-Type: application/json" -d "$JSON" "$REPORT_URL" -s)

if [ $? -eq 0 ]; then
    echo ""
    echo "‚úÖ Check complete! Session ID: $SESSION_ID"
    echo "üìä View results in the web UI"
else
    echo ""
    echo "‚ùå Failed to send results to web app"
    echo "Make sure the app is running at $REPORT_URL"
fi
"""

class UserCreate(BaseModel):
    username: str
    email: str
    full_name: str

class TaskCreate(BaseModel):
    user_id: str
    title: str
    description: str
    status: str = "pending"
    priority: int = 1

def calculate_age(creation_timestamp):
    """Calculate age from creation timestamp"""
    try:
        if isinstance(creation_timestamp, str):
            created = datetime.fromisoformat(creation_timestamp.replace('Z', '+00:00'))
        else:
            created = creation_timestamp
        
        now = datetime.now(timezone.utc)
        delta = now - created
        days = delta.days
        hours = delta.seconds // 3600
        minutes = delta.seconds // 60
        
        if days > 0:
            return f"{days}d"
        elif hours > 0:
            return f"{hours}h"
        else:
            return f"{minutes}m"
    except Exception as e:
        logger.error(f"Error calculating age: {e}")
        return "unknown"

@app.get("/")
async def root():
    return FileResponse(str(static_dir / "index.html"))

@app.get("/scenarios")
async def scenarios_page():
    return FileResponse(str(static_dir / "scenarios.html"))

@app.get("/scenario/{scenario_id}")
async def scenario_detail_page(scenario_id: str):
    return FileResponse(str(static_dir / "scenario-detail.html"))

@app.get("/argocd-scenarios")
async def argocd_scenarios_page():
    return FileResponse(str(static_dir / "argocd-scenarios.html"))

@app.get("/argocd-scenario/{scenario_id}")
async def argocd_scenario_detail_page(scenario_id: str):
    return FileResponse(str(static_dir / "argocd-scenario-detail.html"))

@app.get("/helm-scenarios")
async def helm_scenarios_page():
    return FileResponse(str(static_dir / "helm-scenarios.html"))

@app.get("/helm-scenario/{scenario_id}")
async def helm_scenario_detail_page(scenario_id: str):
    return FileResponse(str(static_dir / "helm-scenario-detail.html"))

@app.get("/gitlab-ci-scenarios")
async def gitlab_ci_scenarios_page():
    return FileResponse(str(static_dir / "gitlab-ci-scenarios.html"))

@app.get("/gitlab-ci-scenario/{scenario_id}")
async def gitlab_ci_scenario_detail_page(scenario_id: str):
    return FileResponse(str(static_dir / "gitlab-ci-scenario-detail.html"))

@app.get("/jenkins-scenarios")
async def jenkins_scenarios_page():
    return FileResponse(str(static_dir / "jenkins-scenarios.html"))

@app.get("/jenkins-scenario/{scenario_id}")
async def jenkins_scenario_detail_page(scenario_id: str):
    return FileResponse(str(static_dir / "jenkins-scenario-detail.html"))

@app.get("/terraform-scenarios")
async def terraform_scenarios_page():
    return FileResponse(str(static_dir / "terraform-scenarios.html"))

@app.get("/terraform-scenario/{scenario_id}")
async def terraform_scenario_detail_page(scenario_id: str):
    return FileResponse(str(static_dir / "terraform-scenario-detail.html"))

@app.get("/ansible-scenarios")
async def ansible_scenarios_page():
    return FileResponse(str(static_dir / "ansible-scenarios.html"))

@app.get("/ansible-scenario/{scenario_id}")
async def ansible_scenario_detail_page(scenario_id: str):
    return FileResponse(str(static_dir / "ansible-scenario-detail.html"))

@app.get("/health")
async def health():
    REQUEST_COUNT.labels(method='GET', endpoint='/health').inc()
    if app_healthy:
        return {"status": "healthy"}
    return Response(content='{"status": "unhealthy"}', status_code=503)

@app.get("/ready")
async def ready():
    REQUEST_COUNT.labels(method='GET', endpoint='/ready').inc()
    if app_ready:
        return {"status": "ready"}
    return Response(content='{"status": "not ready"}', status_code=503)

@app.post("/simulate/crash")
async def simulate_crash():
    global app_healthy
    app_healthy = False
    logger.warning("üî¥ Simulated pod crash - health check will fail")
    return {"status": "unhealthy", "message": "Pod health set to unhealthy"}

@app.post("/simulate/notready")
async def simulate_not_ready():
    global app_ready
    app_ready = False
    logger.warning("‚è∏Ô∏è Simulated pod not ready - readiness check will fail")
    return {"status": "not_ready", "message": "Pod readiness set to not ready"}

@app.post("/reset")
async def reset_health():
    global app_healthy, app_ready
    app_healthy = True
    app_ready = True
    logger.info("‚úÖ Reset pod health and readiness to normal")
    return {"status": "healthy", "message": "Pod health and readiness reset to healthy"}

@app.get("/metrics")
async def metrics():
    REQUEST_COUNT.labels(method='GET', endpoint='/metrics').inc()
    return Response(content=generate_latest(), media_type="text/plain")

@app.get("/api/logs")
async def get_logs():
    return {"logs": list(log_buffer)}

@app.get("/api/config")
async def get_config():
    return {
        "app_env": APP_ENV,
        "app_name": APP_NAME,
        "secret_configured": SECRET_TOKEN != "no-secret-configured",
        "configmap_configured": CONFIGMAP_VALUE != "no-configmap-configured"
    }

@app.get("/api/argocd/url")
async def get_argocd_url():
    """Get the appropriate ArgoCD URL based on availability"""
    import socket

    # Try to check if the ingress hostname resolves
    try:
        socket.gethostbyname('k8s-multi-demo.argocd')
        # If hostname resolves, try the ingress URL with port
        primary_url = 'http://k8s-multi-demo.argocd:30800'
        return {"url": primary_url, "type": "ingress"}
    except socket.gaierror:
        # If hostname doesn't resolve, use NodePort on localhost
        fallback_url = 'http://localhost:30800'
        return {"url": fallback_url, "type": "nodeport"}
    except Exception as e:
        logger.error(f"Error determining ArgoCD URL: {e}")
        # Default to NodePort
        return {"url": "http://localhost:30800", "type": "nodeport"}

@app.get("/api/tools/helm")
async def get_helm_status():
    """Get Helm installation status, version, and release count"""
    result = {
        "installed": False,
        "version": None,
        "release_count": 0,
        "error": None
    }

    # Check Helm CLI version
    try:
        helm_result = subprocess.run(
            ["helm", "version", "--short"],
            capture_output=True,
            text=True,
            timeout=10
        )
        if helm_result.returncode == 0:
            result["installed"] = True
            version_output = helm_result.stdout.strip()
            # Parse version like "v3.17.1+g980d8ac" to get "v3.17.1"
            if version_output.startswith("v"):
                result["version"] = version_output.split("+")[0]
            else:
                result["version"] = version_output
    except FileNotFoundError:
        result["installed"] = False
        result["error"] = "Helm CLI not found"
    except subprocess.TimeoutExpired:
        result["error"] = "Helm version check timed out"
    except Exception as e:
        result["error"] = str(e)

    # Get release count from cluster
    if k8s_available and k8s_core_v1:
        try:
            secrets = k8s_core_v1.list_secret_for_all_namespaces(
                label_selector="owner=helm"
            )
            # Count unique releases (latest revision only)
            releases_dict = {}
            for secret in secrets.items:
                labels = secret.metadata.labels or {}
                name = labels.get("name", "")
                namespace = secret.metadata.namespace
                version = labels.get("version", "1")
                key = f"{namespace}/{name}"
                if key not in releases_dict or int(version) > int(releases_dict[key]):
                    releases_dict[key] = int(version)
            result["release_count"] = len(releases_dict)

            # If CLI not found but releases exist, consider Helm "available"
            if not result["installed"] and result["release_count"] > 0:
                result["installed"] = True
                if not result["version"]:
                    result["version"] = "N/A (releases exist)"
        except Exception as e:
            logger.debug(f"Error counting Helm releases: {e}")

    return result

@app.get("/api/tools/helm/releases")
async def get_helm_releases():
    """Get Helm releases from cluster using Kubernetes API (queries Helm secrets)"""
    result = {"releases": [], "release_count": 0, "error": None}

    if not k8s_available or not k8s_core_v1:
        result["error"] = "Kubernetes API not available"
        return result

    try:
        # Helm stores release data as secrets with label owner=helm
        secrets = k8s_core_v1.list_secret_for_all_namespaces(
            label_selector="owner=helm"
        )

        # Group by release name to get latest revision
        releases_dict = {}
        for secret in secrets.items:
            labels = secret.metadata.labels or {}
            name = labels.get("name", "")
            namespace = secret.metadata.namespace
            status = labels.get("status", "unknown")
            version = labels.get("version", "1")

            # Key by name+namespace to handle same release name in different namespaces
            key = f"{namespace}/{name}"

            # Keep the highest version (latest revision)
            if key not in releases_dict or int(version) > int(releases_dict[key].get("revision", "0")):
                releases_dict[key] = {
                    "name": name,
                    "namespace": namespace,
                    "status": status,
                    "chart": labels.get("chart", ""),
                    "app_version": "",
                    "revision": version
                }

        result["releases"] = list(releases_dict.values())
        result["release_count"] = len(result["releases"])

    except ApiException as e:
        if e.status == 403:
            result["error"] = "No permission to list secrets"
        else:
            result["error"] = f"API error: {e.status}"
        logger.debug(f"Error listing Helm releases: {e}")
    except Exception as e:
        result["error"] = str(e)
        logger.debug(f"Error listing Helm releases: {e}")

    return result

@app.get("/api/tools/argocd")
async def get_argocd_status():
    """Get ArgoCD installation status, version, server status, and app count"""
    global _argocd_server_cache

    result = {
        "installed": False,
        "version": None,
        "server_running": False,
        "app_count": 0,
        "error": None
    }

    # Check ArgoCD CLI version
    try:
        argocd_result = subprocess.run(
            ["argocd", "version", "--client"],
            capture_output=True,
            text=True,
            timeout=10
        )
        if argocd_result.returncode == 0:
            result["installed"] = True
            version_output = argocd_result.stdout.strip()
            # Parse version like "argocd: v3.2.6+65b0293" or just "v3.2.6+65b0293"
            if ":" in version_output:
                version_output = version_output.split(":")[1].strip()
            if version_output.startswith("v"):
                result["version"] = version_output.split("+")[0]
            else:
                result["version"] = version_output
    except FileNotFoundError:
        # CLI not installed, check if server is running in cluster
        pass
    except subprocess.TimeoutExpired:
        result["error"] = "ArgoCD version check timed out"
    except Exception as e:
        logger.debug(f"ArgoCD CLI check error: {e}")

    if not k8s_available or not k8s_apps_v1:
        if not result["installed"]:
            result["error"] = "Kubernetes API not available"
        return result

    # Check if ArgoCD server is running in cluster
    try:
        deployments = k8s_apps_v1.list_namespaced_deployment(namespace="argocd")
        argocd_deployments = [d for d in deployments.items if "argocd" in d.metadata.name.lower()]

        if argocd_deployments:
            if not result["installed"]:
                result["installed"] = True
            server_dep = next((d for d in argocd_deployments if "server" in d.metadata.name.lower()), None)
            if server_dep:
                ready = server_dep.status.ready_replicas or 0
                desired = server_dep.spec.replicas or 1
                result["server_running"] = ready >= desired
                # Get version from image tag if not already set
                if not result["version"] and server_dep.spec.template.spec.containers:
                    image = server_dep.spec.template.spec.containers[0].image
                    if ":" in image:
                        tag = image.split(":")[-1]
                        if tag.startswith("v"):
                            result["version"] = tag.split("+")[0]
    except ApiException as e:
        if e.status == 404:
            pass  # Namespace doesn't exist
        elif e.status == 403:
            result["error"] = "No permission to check argocd namespace"
        else:
            logger.debug(f"Error checking ArgoCD deployments: {e}")
    except Exception as e:
        logger.debug(f"Error checking ArgoCD: {e}")

    # Get app count from ArgoCD Application CRDs
    try:
        custom_api = client.CustomObjectsApi()
        apps = custom_api.list_namespaced_custom_object(
            group="argoproj.io",
            version="v1alpha1",
            namespace="argocd",
            plural="applications"
        )
        result["app_count"] = len(apps.get("items", []))
    except ApiException as e:
        if e.status not in [404, 403]:
            logger.debug(f"Error counting ArgoCD apps: {e}")
    except Exception as e:
        logger.debug(f"Error counting ArgoCD apps: {e}")

    # Cache the results
    _argocd_server_cache["checked"] = True
    _argocd_server_cache["installed"] = result["installed"]
    _argocd_server_cache["server_running"] = result["server_running"]

    return result

@app.get("/api/tools/argocd/apps")
async def get_argocd_apps():
    """Get ArgoCD applications from cluster using Kubernetes API (queries Application CRDs)"""
    result = {"applications": [], "app_count": 0, "error": None}

    if not k8s_available:
        result["error"] = "Kubernetes API not available"
        return result

    try:
        # Use CustomObjectsApi to query ArgoCD Application CRDs
        custom_api = client.CustomObjectsApi()
        apps = custom_api.list_namespaced_custom_object(
            group="argoproj.io",
            version="v1alpha1",
            namespace="argocd",
            plural="applications"
        )

        items = apps.get("items", [])
        for app in items:
            metadata = app.get("metadata", {})
            status = app.get("status", {})
            health = status.get("health", {})
            sync = status.get("sync", {})

            result["applications"].append({
                "name": metadata.get("name", ""),
                "namespace": metadata.get("namespace", "argocd"),
                "health": health.get("status", "Unknown"),
                "sync": sync.get("status", "Unknown"),
                "revision": sync.get("revision", "")[:7] if sync.get("revision") else ""
            })
        result["app_count"] = len(result["applications"])

    except ApiException as e:
        if e.status == 404:
            # ArgoCD CRDs not installed or namespace doesn't exist
            result["error"] = None  # Not an error, just no ArgoCD
        elif e.status == 403:
            result["error"] = "No permission to list ArgoCD applications"
        else:
            result["error"] = f"API error: {e.status}"
        logger.debug(f"Error getting ArgoCD applications: {e}")
    except Exception as e:
        result["error"] = str(e)
        logger.debug(f"Error getting ArgoCD applications: {e}")

    return result

@app.get("/api/cluster/stats")
async def get_cluster_stats():
    """Get Kubernetes cluster statistics - monitors BOTH namespaces"""
    namespaces = ["k8s-multi-demo", "scenarios"]
    
    if not k8s_available or not k8s_apps_v1 or not k8s_core_v1:
        return {
            "deployments": {"count": 0, "details": []},
            "pods": {"count": 0, "details": []},
            "nodes": {"count": 0, "details": []},
            "namespaces": []
        }
    
    deployments_info = {"count": 0, "details": []}
    pods_info = {"count": 0, "details": []}
    nodes_info = {"count": 0, "details": []}
    namespace_info = []
    
    # Get deployments from both namespaces
    for namespace in namespaces:
        try:
            deployments = k8s_apps_v1.list_namespaced_deployment(namespace=namespace)
            deployments_info["count"] += len(deployments.items)
            
            for deployment in deployments.items:
                name = deployment.metadata.name
                spec_replicas = deployment.spec.replicas or 0
                ready_replicas = deployment.status.ready_replicas or 0
                updated_replicas = deployment.status.updated_replicas or 0
                available_replicas = deployment.status.available_replicas or 0
                age = calculate_age(deployment.metadata.creation_timestamp)
                
                deployments_info["details"].append({
                    "name": name,
                    "namespace": namespace,
                    "ready": f"{ready_replicas}/{spec_replicas}",
                    "up_to_date": updated_replicas,
                    "available": available_replicas,
                    "age": age
                })
        except ApiException as e:
            if e.status != 404:
                logger.error(f"Error fetching deployments from {namespace}: {e}")
    
    # Get pods from both namespaces
    for namespace in namespaces:
        try:
            pods = k8s_core_v1.list_namespaced_pod(namespace=namespace)
            pods_info["count"] += len(pods.items)
            
            for pod in pods.items:
                name = pod.metadata.name
                status = pod.status.phase or "Unknown"
                
                container_statuses = pod.status.container_statuses or []
                ready_count = sum(1 for c in container_statuses if c.ready)
                total_count = len(container_statuses)
                ready = f"{ready_count}/{total_count}"
                
                restarts = sum(c.restart_count for c in container_statuses)
                age = calculate_age(pod.metadata.creation_timestamp)
                
                pods_info["details"].append({
                    "name": name,
                    "namespace": namespace,
                    "ready": ready,
                    "status": status,
                    "restarts": restarts,
                    "age": age
                })
        except ApiException as e:
            if e.status != 404:
                logger.error(f"Error fetching pods from {namespace}: {e}")
    
    # Get namespace info
    for namespace in namespaces:
        try:
            ns = k8s_core_v1.read_namespace(name=namespace)
            namespace_info.append({
                "name": namespace,
                "status": ns.status.phase if ns.status else "Unknown",
                "age": calculate_age(ns.metadata.creation_timestamp)
            })
        except ApiException as e:
            if e.status == 404:
                namespace_info.append({
                    "name": namespace,
                    "status": "NotFound",
                    "age": "N/A"
                })
    
    # Get nodes
    try:
        nodes = k8s_core_v1.list_node()
        nodes_info["count"] = len(nodes.items)
        
        for node in nodes.items:
            name = node.metadata.name
            
            conditions = node.status.conditions or []
            ready_condition = next((c for c in conditions if c.type == "Ready"), None)
            status = "Ready" if ready_condition and ready_condition.status == "True" else "NotReady"
            
            labels = node.metadata.labels or {}
            roles = []
            if "node-role.kubernetes.io/control-plane" in labels or "node-role.kubernetes.io/master" in labels:
                roles.append("control-plane")
            if "node-role.kubernetes.io/worker" in labels:
                roles.append("worker")
            role = ",".join(roles) if roles else "worker"
            
            age = calculate_age(node.metadata.creation_timestamp)
            version = node.status.node_info.kubelet_version if node.status.node_info else "unknown"
            
            nodes_info["details"].append({
                "name": name,
                "status": status,
                "roles": role,
                "age": age,
                "version": version
            })
    except ApiException as e:
        logger.error(f"Error fetching nodes: {e}")
    
    return {
        "deployments": deployments_info,
        "pods": pods_info,
        "nodes": nodes_info,
        "namespaces": namespace_info
    }

# ============================================
# PREREQUISITES ENDPOINTS
# ============================================

@app.get("/api/prerequisites/checker.sh")
async def get_checker_script():
    """Returns a bash script that checks tools on user's host machine and reports back"""
    logger.info("Serving prerequisites checker script")
    return Response(content=CHECKER_SCRIPT, media_type="text/x-shellscript")

@app.post("/api/prerequisites/report")
async def receive_prerequisite_report(data: dict):
    """Receives tool check results from user's host machine"""
    import uuid
    session_id = data.get("session_id") or str(uuid.uuid4())

    prerequisite_reports[session_id] = {
        "session_id": session_id,
        "tools": data.get("tools", {}),
        "timestamp": datetime.utcnow().isoformat()
    }

    # Store as 'latest' as well for easy retrieval
    prerequisite_reports["latest"] = prerequisite_reports[session_id]

    logger.info(f"Received prerequisite report for session {session_id}")
    return {"session_id": session_id, "status": "received"}

@app.get("/api/prerequisites/status/{session_id}")
async def get_prerequisite_status(session_id: str):
    """Returns the status report for a session"""
    if session_id not in prerequisite_reports:
        raise HTTPException(status_code=404, detail="Session not found. Please run the checker script first.")

    return prerequisite_reports[session_id]

@app.get("/api/prerequisites/installer.sh")
async def get_installer_script(tools: str = ""):
    """Returns custom installer script for selected tools"""
    tool_list = [t.strip() for t in tools.split(",") if t.strip()] if tools else []

    if not tool_list:
        raise HTTPException(status_code=400, detail="No tools specified. Use ?tools=kubectl,helm,terraform")

    # Validate tool names
    valid_tools = {"docker", "kubectl", "kind", "helm", "terraform", "ansible", "gitlab-runner"}
    invalid_tools = [t for t in tool_list if t not in valid_tools]
    if invalid_tools:
        raise HTTPException(status_code=400, detail=f"Invalid tool names: {', '.join(invalid_tools)}")

    logger.info(f"Generating installer script for tools: {', '.join(tool_list)}")
    script = generate_installer_script(tool_list)

    return Response(
        content=script,
        media_type="text/x-shellscript",
        headers={"Content-Disposition": "attachment; filename=install-prerequisites.sh"}
    )

def generate_installer_script(tools):
    """Generate custom installer script for selected tools"""

    # Script header with colors and helper functions
    header = '''#!/bin/bash
# Prerequisites Installer Script
# Generated by Kubernetes Production Simulator
# Tools to install: ''' + ', '.join(tools) + '''

set -e

# Colors
RED='\\033[0;31m'
GREEN='\\033[0;32m'
BLUE='\\033[0;34m'
YELLOW='\\033[1;33m'
CYAN='\\033[0;36m'
NC='\\033[0m' # No Color

print_header() {
    echo ""
    echo -e "${CYAN}============================================${NC}"
    echo -e "${CYAN}$1${NC}"
    echo -e "${CYAN}============================================${NC}"
    echo ""
}

print_step() {
    echo -e "${BLUE}‚ñ∂ $1${NC}"
}

print_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

print_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

print_info() {
    echo -e "${CYAN}‚ÑπÔ∏è  $1${NC}"
}

# Detect OS
if [ -f /etc/os-release ]; then
    . /etc/os-release
    OS=$ID
else
    OS=$(uname -s)
fi

# Detect if WSL
if grep -qi microsoft /proc/version 2>/dev/null; then
    IS_WSL=true
    print_info "Detected: Windows Subsystem for Linux (WSL)"
else
    IS_WSL=false
    print_info "Detected: $OS"
fi

print_header "INSTALLING SELECTED PREREQUISITES"
echo "This script will install: ''' + ', '.join(tools) + '''"
echo ""
read -p "Press Enter to continue or Ctrl+C to cancel..."
echo ""

'''

    # Installation functions for each tool
    install_functions = {
        "docker": '''
print_header "Installing Docker"
print_step "Removing old versions..."
sudo apt-get remove -y docker docker-engine docker.io containerd runc 2>/dev/null || true

print_step "Installing dependencies..."
sudo apt-get update -qq
sudo apt-get install -y ca-certificates curl gnupg lsb-release

print_step "Adding Docker GPG key..."
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

print_step "Adding Docker repository..."
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

print_step "Installing Docker..."
sudo apt-get update -qq
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

print_step "Adding user to docker group..."
sudo usermod -aG docker $USER

print_success "Docker installed!"
print_info "You may need to log out and log back in for group changes to take effect"
echo ""
''',
        "kubectl": '''
print_header "Installing kubectl"
print_step "Downloading kubectl..."
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

print_step "Installing kubectl..."
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
rm kubectl

print_success "kubectl installed!"
echo ""
''',
        "kind": '''
print_header "Installing kind"
print_step "Downloading kind..."
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64

print_step "Installing kind..."
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

print_success "kind installed!"
echo ""
''',
        "helm": '''
print_header "Installing Helm"
print_step "Downloading and installing Helm..."
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

print_success "Helm installed!"
echo ""
''',
        "terraform": '''
print_header "Installing Terraform"
print_step "Adding HashiCorp GPG key..."
wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg

print_step "Adding HashiCorp repository..."
echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list

print_step "Installing Terraform..."
sudo apt-get update -qq
sudo apt-get install -y terraform

print_success "Terraform installed!"
echo ""
''',
        "ansible": '''
print_header "Installing Ansible"
print_step "Adding Ansible repository..."
sudo apt-get update -qq
sudo apt-get install -y software-properties-common
sudo add-apt-repository --yes --update ppa:ansible/ansible

print_step "Installing Ansible..."
sudo apt-get install -y ansible

print_success "Ansible installed!"
echo ""
''',
        "gitlab-runner": '''
print_header "Installing GitLab Runner"
print_step "Adding GitLab Runner repository..."
curl -L "https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh" | sudo bash

print_step "Installing GitLab Runner..."
sudo apt-get install -y gitlab-runner

print_success "GitLab Runner installed!"
echo ""
'''
    }

    # Build the complete script
    script = header

    for tool in tools:
        if tool in install_functions:
            script += install_functions[tool]

    # Footer with summary
    footer = '''
print_header "INSTALLATION COMPLETE"
echo -e "${GREEN}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó${NC}"
echo -e "${GREEN}‚ïë              INSTALLATION SUCCESSFUL!                        ‚ïë${NC}"
echo -e "${GREEN}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù${NC}"
echo ""
echo -e "${CYAN}Installed tools:${NC}"
'''

    for tool in tools:
        footer += f'echo "  ‚úì {tool}"\n'

    footer += '''
echo ""
echo -e "${CYAN}Next steps:${NC}"
echo "  1. Verify installations by running the checker script again"
echo "  2. If Docker was installed, log out and log back in"
echo "  3. Start using the Kubernetes Production Simulator!"
echo ""
print_success "You're all set! üöÄ"
'''

    script += footer
    return script

# Database endpoints
@app.post("/api/database/init")
async def initialize_database(db: Session = Depends(get_db)):
    try:
        init_db()
        return {"message": "Database initialized successfully"}
    except Exception as e:
        logger.error(f"Database initialization error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/database/status")
async def database_status():
    try:
        is_connected, message = check_db_connection()
        stats = get_db_stats() if is_connected else {}
        return {"connected": is_connected, "message": message, "stats": stats}
    except Exception as e:
        logger.error(f"Database status check error: {e}")
        return {"connected": False, "error": str(e)}

@app.get("/api/db/stats")
async def get_database_stats():
    """Get database statistics for the Stateful-DB tab"""
    try:
        stats = get_db_stats()
        return stats
    except Exception as e:
        logger.error(f"Error getting database stats: {e}")
        return {"connected": False, "error": str(e)}

@app.get("/api/db/info")
async def get_database_info():
    """Get database StatefulSet, Secret, and ConfigMap information"""
    try:
        if not k8s_available or not k8s_apps_v1 or not k8s_core_v1:
            return {
                "uses_secret": False,
                "uses_configmap": False,
                "error": "Kubernetes API not available"
            }

        namespace = "k8s-multi-demo"
        info = {
            "uses_secret": False,
            "secret_name": None,
            "uses_configmap": False,
            "configmap_name": None
        }

        # Check if Secret exists
        try:
            secret = k8s_core_v1.read_namespaced_secret(name="postgres-secret", namespace=namespace)
            info["uses_secret"] = True
            info["secret_name"] = secret.metadata.name
        except ApiException as e:
            if e.status != 404:
                logger.error(f"Error fetching Secret: {e}")

        # Check if ConfigMap exists
        try:
            configmap = k8s_core_v1.read_namespaced_config_map(name="postgres-config", namespace=namespace)
            info["uses_configmap"] = True
            info["configmap_name"] = configmap.metadata.name
        except ApiException as e:
            if e.status != 404:
                logger.error(f"Error fetching ConfigMap: {e}")

        return info
    except Exception as e:
        logger.error(f"Error in get_database_info: {e}")
        return {
            "uses_secret": False,
            "uses_configmap": False,
            "error": str(e)
        }

@app.post("/api/users")
async def create_user(user: UserCreate, db: Session = Depends(get_db)):
    try:
        db_user = User(username=user.username, email=user.email, full_name=user.full_name)
        db.add(db_user)
        db.commit()
        db.refresh(db_user)
        return db_user.to_dict()
    except Exception as e:
        db.rollback()
        error_msg = str(e)
        # Check for specific database errors and provide user-friendly messages
        if "duplicate key" in error_msg.lower() and "username" in error_msg.lower():
            raise HTTPException(status_code=400, detail=f"Username '{user.username}' already exists. Please choose a different username.")
        elif "duplicate key" in error_msg.lower() and "email" in error_msg.lower():
            raise HTTPException(status_code=400, detail=f"Email '{user.email}' already exists. Please use a different email.")
        else:
            logger.error(f"Error creating user: {e}")
            raise HTTPException(status_code=500, detail="Failed to create user. Please try again.")

@app.get("/api/users")
async def list_users(db: Session = Depends(get_db)):
    try:
        users = db.query(User).all()
        return {"users": [user.to_dict() for user in users]}
    except Exception as e:
        logger.error(f"Error listing users: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/tasks")
async def create_task(task: TaskCreate, db: Session = Depends(get_db)):
    try:
        db_task = Task(user_id=task.user_id, title=task.title, description=task.description, status=task.status, priority=task.priority)
        db.add(db_task)
        db.commit()
        db.refresh(db_task)
        return db_task.to_dict()
    except Exception as e:
        db.rollback()
        error_msg = str(e)
        logger.error(f"Error creating task: {e}")
        if "foreign key" in error_msg.lower():
            raise HTTPException(status_code=400, detail="Invalid user ID. Please select a valid user.")
        else:
            raise HTTPException(status_code=500, detail="Failed to create task. Please try again.")

@app.get("/api/tasks")
async def list_tasks(db: Session = Depends(get_db)):
    try:
        tasks = db.query(Task).all()
        return {"tasks": [task.to_dict() for task in tasks]}
    except Exception as e:
        logger.error(f"Error listing tasks: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Load test endpoints (unchanged)
@app.post("/api/load-test/start")
async def start_load_test():
    global load_test_running, load_test_task
    if load_test_running:
        return {"message": "Load test already running"}
    async def generate_load():
        global load_test_running
        logger.info("Load test started")
        while load_test_running:
            try:
                _ = sum(i * i for i in range(10000))
                await asyncio.sleep(0.1)
            except Exception as e:
                logger.error(f"Load test error: {e}")
                break
        logger.info("Load test stopped")
    load_test_running = True
    load_test_task = asyncio.create_task(generate_load())
    return {"message": "Load test started", "status": "running"}

@app.post("/api/load-test/stop")
async def stop_load_test():
    global load_test_running, load_test_task
    if not load_test_running:
        return {"message": "Load test not running"}
    load_test_running = False
    if load_test_task and not load_test_task.done():
        load_test_task.cancel()
        try:
            await load_test_task
        except asyncio.CancelledError:
            pass
    return {"message": "Load test stopped", "status": "stopped"}

@app.get("/api/load-test/status")
async def load_test_status():
    return {"running": load_test_running, "status": "running" if load_test_running else "stopped"}

@app.get("/api/scenarios")
async def get_scenarios():
    """Get list of all available scenarios"""
    try:
        # Try multiple possible locations for scenarios directory
        possible_paths = [
            Path("/scenarios"),  # Docker mount
            Path("/app/k8s-scenarios"),  # Alternative
            Path(__file__).parent.parent.parent / "k8s-scenarios"  # Dev
        ]
        
        scenarios_dir = None
        for path in possible_paths:
            if path.exists() and path.is_dir():
                scenarios_dir = path
                logger.info(f"Found scenarios at: {scenarios_dir}")
                break
        
        if not scenarios_dir:
            logger.warning("No scenarios directory found")
            return {"scenarios": []}
        
        scenarios = []
        scenario_dirs = sorted([d for d in scenarios_dir.iterdir() if d.is_dir()])
        logger.info(f"Found {len(scenario_dirs)} scenario directories")
        
        for scenario_dir in scenario_dirs:
            try:
                readme_path = scenario_dir / "README.md"
                commands_path = scenario_dir / "commands.json"
                
                scenario_info = {
                    "id": scenario_dir.name,
                    "name": scenario_dir.name.replace("-", " ").title(),
                    "description": "No description available",
                    "difficulty": "medium",
                    "duration": "20 min",
                    "special": "special" in scenario_dir.name.lower(),
                    "readme": "",
                    "command_count": 0,
                    "namespace": "scenarios"
                }
                
                # Read README
                if readme_path.exists():
                    with open(readme_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
                        if lines:
                            scenario_info["description"] = lines[0][:200]
                        scenario_info["readme"] = content
                
                # Read commands.json
                if commands_path.exists():
                    with open(commands_path, 'r', encoding='utf-8') as f:
                        commands_data = json.load(f)
                        scenario_info["command_count"] = len(commands_data.get("commands", []))
                        scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                        scenario_info["duration"] = commands_data.get("duration", "20 min")
                
                # Count YAML files
                yaml_files = list(scenario_dir.glob("*.yaml")) + list(scenario_dir.glob("*.yml"))
                scenario_info["yaml_file_count"] = len(yaml_files)
                
                scenarios.append(scenario_info)
            except Exception as e:
                logger.error(f"Error processing scenario {scenario_dir.name}: {e}")
                continue
        
        logger.info(f"Processed {len(scenarios)} scenarios")
        return {"scenarios": scenarios}
    except Exception as e:
        logger.error(f"Fatal error in get_scenarios: {e}", exc_info=True)
        return {"scenarios": [], "error": str(e)}

@app.get("/api/scenarios/{scenario_id}")
async def get_scenario(scenario_id: str):
    """Get detailed scenario info including YAML files"""
    try:
        possible_paths = [Path("/scenarios"), Path("/app/k8s-scenarios"), Path(__file__).parent.parent.parent / "k8s-scenarios"]
        
        scenario_dir = None
        for base_path in possible_paths:
            test_path = base_path / scenario_id
            if test_path.exists() and test_path.is_dir():
                scenario_dir = test_path
                break
        
        if not scenario_dir:
            raise HTTPException(status_code=404, detail=f"Scenario '{scenario_id}' not found")
        
        logger.info(f"Loading scenario from: {scenario_dir}")
        
        scenario_info = {
            "id": scenario_id,
            "name": scenario_id.replace("-", " ").title(),
            "readme": "",
            "commands": [],
            "yaml_files": [],
            "difficulty": "medium",
            "duration": "20 min",
            "namespace": "scenarios"
        }
        
        # Read README
        readme_path = scenario_dir / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                scenario_info["readme"] = f.read()
        else:
            scenario_info["readme"] = "# No README available"
        
        # Read commands.json
        commands_path = scenario_dir / "commands.json"
        if commands_path.exists():
            with open(commands_path, 'r', encoding='utf-8') as f:
                commands_data = json.load(f)
                scenario_info["commands"] = commands_data.get("commands", [])
                scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                scenario_info["duration"] = commands_data.get("duration", "20 min")
        
        # Read ALL YAML files
        yaml_files = list(scenario_dir.glob("*.yaml")) + list(scenario_dir.glob("*.yml"))
        
        # Sort: deployment/statefulset first, then service, then others
        def yaml_sort_key(p):
            name = p.name.lower()
            if 'deployment' in name or 'statefulset' in name:
                return (0, name)
            elif 'service' in name:
                return (1, name)
            else:
                return (2, name)
        
        yaml_files = sorted(yaml_files, key=yaml_sort_key)
        logger.info(f"Found {len(yaml_files)} YAML files for {scenario_id}")
        
        for yaml_file in yaml_files:
            try:
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    scenario_info["yaml_files"].append({
                        "name": yaml_file.name,
                        "content": content
                    })
            except Exception as e:
                logger.error(f"Error reading {yaml_file.name}: {e}")
                scenario_info["yaml_files"].append({
                    "name": yaml_file.name,
                    "content": f"# Error loading file: {str(e)}"
                })
        
        logger.info(f"Scenario {scenario_id}: {len(scenario_info['commands'])} commands, {len(scenario_info['yaml_files'])} YAML files")
        return scenario_info
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in get_scenario: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/scenarios/{scenario_id}/validate")
async def validate_scenario(scenario_id: str):
    """Run validation script"""
    try:
        logger.info(f"Validating scenario: {scenario_id}")
        
        possible_paths = [Path("/scenarios"), Path("/app/k8s-scenarios"), Path(__file__).parent.parent.parent / "k8s-scenarios"]
        
        scenario_dir = None
        for base_path in possible_paths:
            test_path = base_path / scenario_id
            if test_path.exists():
                scenario_dir = test_path
                break
        
        if not scenario_dir:
            return {"success": False, "message": f"Scenario not found: {scenario_id}", "output": "", "error": ""}
        
        validate_script = scenario_dir / "validate.sh"
        if not validate_script.exists():
            return {"success": False, "message": "No validation script found", "output": "", "error": ""}
        
        result = subprocess.run(["bash", str(validate_script)], capture_output=True, text=True, timeout=60, cwd=str(scenario_dir))
        
        return {
            "success": result.returncode == 0,
            "message": "Validation completed" if result.returncode == 0 else "Validation failed",
            "output": result.stdout,
            "error": result.stderr,
            "returncode": result.returncode
        }
    except subprocess.TimeoutExpired:
        return {"success": False, "message": "Validation timed out", "output": "", "error": "Timeout"}
    except Exception as e:
        logger.error(f"Validation error: {e}")
        return {"success": False, "message": f"Error: {str(e)}", "output": "", "error": str(e)}

@app.get("/api/argocd-scenarios")
async def get_argocd_scenarios():
    """Get list of all available ArgoCD scenarios"""
    try:
        possible_paths = [
            Path("/argocd-scenarios"),
            Path("/app/argocd-scenarios"),
            Path(__file__).parent.parent.parent / "argocd-scenarios"
        ]

        scenarios_dir = None
        for path in possible_paths:
            if path.exists() and path.is_dir():
                scenarios_dir = path
                logger.info(f"Found ArgoCD scenarios at: {scenarios_dir}")
                break

        if not scenarios_dir:
            logger.warning("No ArgoCD scenarios directory found")
            return {"scenarios": []}

        scenarios = []
        scenario_dirs = sorted([d for d in scenarios_dir.iterdir() if d.is_dir()])
        logger.info(f"Found {len(scenario_dirs)} ArgoCD scenario directories")

        for scenario_dir in scenario_dirs:
            try:
                readme_path = scenario_dir / "README.md"
                commands_path = scenario_dir / "commands.json"

                scenario_info = {
                    "id": scenario_dir.name,
                    "name": scenario_dir.name.replace("-", " ").title(),
                    "description": "No description available",
                    "difficulty": "medium",
                    "duration": "15 min",
                    "readme": "",
                    "command_count": 0,
                    "namespace": "argocd"
                }

                if readme_path.exists():
                    with open(readme_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
                        if lines:
                            scenario_info["description"] = lines[0][:200]
                        scenario_info["readme"] = content

                if commands_path.exists():
                    with open(commands_path, 'r', encoding='utf-8') as f:
                        commands_data = json.load(f)
                        scenario_info["command_count"] = len(commands_data.get("commands", []))
                        scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                        scenario_info["duration"] = commands_data.get("duration", "15 min")

                yaml_files = list(scenario_dir.glob("*.yaml")) + list(scenario_dir.glob("*.yml"))
                scenario_info["yaml_file_count"] = len(yaml_files)

                scenarios.append(scenario_info)
            except Exception as e:
                logger.error(f"Error processing ArgoCD scenario {scenario_dir.name}: {e}")
                continue

        logger.info(f"Processed {len(scenarios)} ArgoCD scenarios")
        return {"scenarios": scenarios}
    except Exception as e:
        logger.error(f"Fatal error in get_argocd_scenarios: {e}", exc_info=True)
        return {"scenarios": [], "error": str(e)}

@app.get("/api/argocd-scenarios/{scenario_id}")
async def get_argocd_scenario(scenario_id: str):
    """Get detailed ArgoCD scenario info including YAML files"""
    try:
        possible_paths = [
            Path("/argocd-scenarios"),
            Path("/app/argocd-scenarios"),
            Path(__file__).parent.parent.parent / "argocd-scenarios"
        ]

        scenario_dir = None
        for base_path in possible_paths:
            test_path = base_path / scenario_id
            if test_path.exists() and test_path.is_dir():
                scenario_dir = test_path
                break

        if not scenario_dir:
            raise HTTPException(status_code=404, detail=f"ArgoCD scenario '{scenario_id}' not found")

        logger.info(f"Loading ArgoCD scenario from: {scenario_dir}")

        scenario_info = {
            "id": scenario_id,
            "name": scenario_id.replace("-", " ").title(),
            "readme": "",
            "commands": [],
            "yaml_files": [],
            "difficulty": "medium",
            "duration": "15 min",
            "namespace": "argocd"
        }

        readme_path = scenario_dir / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                scenario_info["readme"] = f.read()
        else:
            scenario_info["readme"] = "# No README available"

        commands_path = scenario_dir / "commands.json"
        if commands_path.exists():
            with open(commands_path, 'r', encoding='utf-8') as f:
                commands_data = json.load(f)
                scenario_info["commands"] = commands_data.get("commands", [])
                scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                scenario_info["duration"] = commands_data.get("duration", "15 min")

        # Collect YAML files from scenario dir and subdirectories
        yaml_files = []
        for pattern in ["*.yaml", "*.yml"]:
            yaml_files.extend(scenario_dir.glob(pattern))
            yaml_files.extend(scenario_dir.glob(f"**/{pattern}"))

        # Deduplicate and sort
        seen = set()
        unique_yaml = []
        for f in yaml_files:
            if f.resolve() not in seen:
                seen.add(f.resolve())
                unique_yaml.append(f)

        def yaml_sort_key(p):
            name = p.name.lower()
            if 'application' in name or 'parent' in name:
                return (0, name)
            elif 'project' in name:
                return (1, name)
            elif 'deployment' in name or 'rollout' in name:
                return (2, name)
            elif 'service' in name:
                return (3, name)
            else:
                return (4, name)

        unique_yaml = sorted(unique_yaml, key=yaml_sort_key)
        logger.info(f"Found {len(unique_yaml)} YAML files for ArgoCD scenario {scenario_id}")

        for yaml_file in unique_yaml:
            try:
                rel_path = yaml_file.relative_to(scenario_dir)
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    scenario_info["yaml_files"].append({
                        "name": str(rel_path),
                        "content": content
                    })
            except Exception as e:
                logger.error(f"Error reading {yaml_file.name}: {e}")
                scenario_info["yaml_files"].append({
                    "name": yaml_file.name,
                    "content": f"# Error loading file: {str(e)}"
                })

        logger.info(f"ArgoCD scenario {scenario_id}: {len(scenario_info['commands'])} commands, {len(scenario_info['yaml_files'])} YAML files")
        return scenario_info
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in get_argocd_scenario: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/helm-scenarios")
async def get_helm_scenarios():
    """Get list of all available Helm scenarios"""
    try:
        possible_paths = [
            Path("/helm-scenarios"),
            Path("/app/helm-scenarios"),
            Path(__file__).parent.parent.parent / "helm-scenarios"
        ]

        scenarios_dir = None
        for path in possible_paths:
            if path.exists() and path.is_dir():
                scenarios_dir = path
                logger.info(f"Found Helm scenarios at: {scenarios_dir}")
                break

        if not scenarios_dir:
            logger.warning("No Helm scenarios directory found")
            return {"scenarios": []}

        scenarios = []
        scenario_dirs = sorted([d for d in scenarios_dir.iterdir() if d.is_dir()])
        logger.info(f"Found {len(scenario_dirs)} Helm scenario directories")

        for scenario_dir in scenario_dirs:
            try:
                readme_path = scenario_dir / "README.md"
                commands_path = scenario_dir / "commands.json"

                scenario_info = {
                    "id": scenario_dir.name,
                    "name": scenario_dir.name.replace("-", " ").title(),
                    "description": "No description available",
                    "difficulty": "medium",
                    "duration": "20 min",
                    "readme": "",
                    "command_count": 0,
                    "namespace": "helm-scenarios"
                }

                if readme_path.exists():
                    with open(readme_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
                        if lines:
                            scenario_info["description"] = lines[0][:200]
                        scenario_info["readme"] = content

                if commands_path.exists():
                    with open(commands_path, 'r', encoding='utf-8') as f:
                        commands_data = json.load(f)
                        scenario_info["command_count"] = len(commands_data.get("commands", []))
                        scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                        scenario_info["duration"] = commands_data.get("duration", "20 min")

                yaml_files = list(scenario_dir.glob("*.yaml")) + list(scenario_dir.glob("*.yml"))
                scenario_info["yaml_file_count"] = len(yaml_files)

                scenarios.append(scenario_info)
            except Exception as e:
                logger.error(f"Error processing Helm scenario {scenario_dir.name}: {e}")
                continue

        logger.info(f"Processed {len(scenarios)} Helm scenarios")
        return {"scenarios": scenarios}
    except Exception as e:
        logger.error(f"Fatal error in get_helm_scenarios: {e}", exc_info=True)
        return {"scenarios": [], "error": str(e)}

@app.get("/api/helm-scenarios/{scenario_id}")
async def get_helm_scenario(scenario_id: str):
    """Get detailed Helm scenario info including YAML files"""
    try:
        possible_paths = [
            Path("/helm-scenarios"),
            Path("/app/helm-scenarios"),
            Path(__file__).parent.parent.parent / "helm-scenarios"
        ]

        scenario_dir = None
        for base_path in possible_paths:
            test_path = base_path / scenario_id
            if test_path.exists() and test_path.is_dir():
                scenario_dir = test_path
                break

        if not scenario_dir:
            raise HTTPException(status_code=404, detail=f"Helm scenario '{scenario_id}' not found")

        logger.info(f"Loading Helm scenario from: {scenario_dir}")

        scenario_info = {
            "id": scenario_id,
            "name": scenario_id.replace("-", " ").title(),
            "readme": "",
            "commands": [],
            "yaml_files": [],
            "difficulty": "medium",
            "duration": "20 min",
            "namespace": "helm-scenarios"
        }

        readme_path = scenario_dir / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                scenario_info["readme"] = f.read()
        else:
            scenario_info["readme"] = "# No README available"

        commands_path = scenario_dir / "commands.json"
        if commands_path.exists():
            with open(commands_path, 'r', encoding='utf-8') as f:
                commands_data = json.load(f)
                scenario_info["commands"] = commands_data.get("commands", [])
                scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                scenario_info["duration"] = commands_data.get("duration", "20 min")

        # Collect YAML files from scenario dir and subdirectories
        yaml_files = []
        for pattern in ["*.yaml", "*.yml"]:
            yaml_files.extend(scenario_dir.glob(pattern))
            yaml_files.extend(scenario_dir.glob(f"**/{pattern}"))

        # Deduplicate and sort
        seen = set()
        unique_yaml = []
        for f in yaml_files:
            if f.resolve() not in seen:
                seen.add(f.resolve())
                unique_yaml.append(f)

        def yaml_sort_key(p):
            name = p.name.lower()
            if 'chart' in name:
                return (0, name)
            elif 'values' in name:
                return (1, name)
            elif 'deployment' in name:
                return (2, name)
            elif 'service' in name:
                return (3, name)
            else:
                return (4, name)

        unique_yaml = sorted(unique_yaml, key=yaml_sort_key)
        logger.info(f"Found {len(unique_yaml)} YAML files for Helm scenario {scenario_id}")

        for yaml_file in unique_yaml:
            try:
                rel_path = yaml_file.relative_to(scenario_dir)
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    scenario_info["yaml_files"].append({
                        "name": str(rel_path),
                        "content": content
                    })
            except Exception as e:
                logger.error(f"Error reading {yaml_file.name}: {e}")
                scenario_info["yaml_files"].append({
                    "name": yaml_file.name,
                    "content": f"# Error loading file: {str(e)}"
                })

        logger.info(f"Helm scenario {scenario_id}: {len(scenario_info['commands'])} commands, {len(scenario_info['yaml_files'])} YAML files")
        return scenario_info
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in get_helm_scenario: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/gitlab-ci-scenarios")
async def get_gitlab_ci_scenarios():
    """Get list of all available GitLab CI scenarios"""
    try:
        possible_paths = [
            Path("/gitlab-ci-scenarios"),
            Path("/app/gitlab-ci-scenarios"),
            Path(__file__).parent.parent.parent / "gitlab-ci-scenarios"
        ]

        scenarios_dir = None
        for path in possible_paths:
            if path.exists() and path.is_dir():
                scenarios_dir = path
                logger.info(f"Found GitLab CI scenarios at: {scenarios_dir}")
                break

        if not scenarios_dir:
            logger.warning("No GitLab CI scenarios directory found")
            return {"scenarios": []}

        scenarios = []
        scenario_dirs = sorted([d for d in scenarios_dir.iterdir() if d.is_dir()])
        logger.info(f"Found {len(scenario_dirs)} GitLab CI scenario directories")

        for scenario_dir in scenario_dirs:
            try:
                readme_path = scenario_dir / "README.md"
                commands_path = scenario_dir / "commands.json"

                scenario_info = {
                    "id": scenario_dir.name,
                    "name": scenario_dir.name.replace("-", " ").title(),
                    "description": "No description available",
                    "difficulty": "medium",
                    "duration": "15 min",
                    "readme": "",
                    "command_count": 0,
                    "namespace": "gitlab-ci-scenarios"
                }

                if readme_path.exists():
                    with open(readme_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
                        if lines:
                            scenario_info["description"] = lines[0][:200]
                        scenario_info["readme"] = content

                if commands_path.exists():
                    with open(commands_path, 'r', encoding='utf-8') as f:
                        commands_data = json.load(f)
                        scenario_info["command_count"] = len(commands_data.get("commands", []))
                        scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                        scenario_info["duration"] = commands_data.get("duration", "15 min")

                yaml_files = list(scenario_dir.glob("*.yaml")) + list(scenario_dir.glob("*.yml"))
                scenario_info["yaml_file_count"] = len(yaml_files)

                scenarios.append(scenario_info)
            except Exception as e:
                logger.error(f"Error processing GitLab CI scenario {scenario_dir.name}: {e}")
                continue

        logger.info(f"Processed {len(scenarios)} GitLab CI scenarios")
        return {"scenarios": scenarios}
    except Exception as e:
        logger.error(f"Fatal error in get_gitlab_ci_scenarios: {e}", exc_info=True)
        return {"scenarios": [], "error": str(e)}

@app.get("/api/gitlab-ci-scenarios/{scenario_id}")
async def get_gitlab_ci_scenario(scenario_id: str):
    """Get detailed GitLab CI scenario info including YAML files"""
    try:
        possible_paths = [
            Path("/gitlab-ci-scenarios"),
            Path("/app/gitlab-ci-scenarios"),
            Path(__file__).parent.parent.parent / "gitlab-ci-scenarios"
        ]

        scenario_dir = None
        for base_path in possible_paths:
            test_path = base_path / scenario_id
            if test_path.exists() and test_path.is_dir():
                scenario_dir = test_path
                break

        if not scenario_dir:
            raise HTTPException(status_code=404, detail=f"GitLab CI scenario '{scenario_id}' not found")

        logger.info(f"Loading GitLab CI scenario from: {scenario_dir}")

        scenario_info = {
            "id": scenario_id,
            "name": scenario_id.replace("-", " ").title(),
            "readme": "",
            "commands": [],
            "yaml_files": [],
            "difficulty": "medium",
            "duration": "15 min",
            "namespace": "gitlab-ci-scenarios"
        }

        readme_path = scenario_dir / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                scenario_info["readme"] = f.read()
        else:
            scenario_info["readme"] = "# No README available"

        commands_path = scenario_dir / "commands.json"
        if commands_path.exists():
            with open(commands_path, 'r', encoding='utf-8') as f:
                commands_data = json.load(f)
                scenario_info["commands"] = commands_data.get("commands", [])
                scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                scenario_info["duration"] = commands_data.get("duration", "15 min")

        # Collect YAML files from scenario dir and subdirectories
        yaml_files = []
        for pattern in ["*.yaml", "*.yml"]:
            yaml_files.extend(scenario_dir.glob(pattern))
            yaml_files.extend(scenario_dir.glob(f"**/{pattern}"))

        # Deduplicate and sort
        seen = set()
        unique_yaml = []
        for f in yaml_files:
            if f.resolve() not in seen:
                seen.add(f.resolve())
                unique_yaml.append(f)

        def yaml_sort_key(p):
            name = p.name.lower()
            if 'pipeline' in name or 'gitlab-ci' in name:
                return (0, name)
            elif 'deployment' in name:
                return (1, name)
            elif 'service' in name:
                return (2, name)
            else:
                return (3, name)

        unique_yaml = sorted(unique_yaml, key=yaml_sort_key)
        logger.info(f"Found {len(unique_yaml)} YAML files for GitLab CI scenario {scenario_id}")

        for yaml_file in unique_yaml:
            try:
                rel_path = yaml_file.relative_to(scenario_dir)
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    scenario_info["yaml_files"].append({
                        "name": str(rel_path),
                        "content": content
                    })
            except Exception as e:
                logger.error(f"Error reading {yaml_file.name}: {e}")
                scenario_info["yaml_files"].append({
                    "name": yaml_file.name,
                    "content": f"# Error loading file: {str(e)}"
                })

        logger.info(f"GitLab CI scenario {scenario_id}: {len(scenario_info['commands'])} commands, {len(scenario_info['yaml_files'])} YAML files")
        return scenario_info
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in get_gitlab_ci_scenario: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/jenkins-scenarios")
async def get_jenkins_scenarios():
    """Get list of all available Jenkins scenarios"""
    try:
        possible_paths = [
            Path("/jenkins-scenarios"),
            Path("/app/jenkins-scenarios"),
            Path(__file__).parent.parent.parent / "jenkins-scenarios"
        ]

        scenarios_dir = None
        for path in possible_paths:
            if path.exists() and path.is_dir():
                scenarios_dir = path
                logger.info(f"Found Jenkins scenarios at: {scenarios_dir}")
                break

        if not scenarios_dir:
            logger.warning("No Jenkins scenarios directory found")
            return {"scenarios": []}

        scenarios = []
        scenario_dirs = sorted([d for d in scenarios_dir.iterdir() if d.is_dir()])
        logger.info(f"Found {len(scenario_dirs)} Jenkins scenario directories")

        for scenario_dir in scenario_dirs:
            try:
                readme_path = scenario_dir / "README.md"
                commands_path = scenario_dir / "commands.json"

                scenario_info = {
                    "id": scenario_dir.name,
                    "name": scenario_dir.name.replace("-", " ").title(),
                    "description": "No description available",
                    "difficulty": "medium",
                    "duration": "15 min",
                    "readme": "",
                    "command_count": 0,
                    "namespace": "jenkins-scenarios"
                }

                if readme_path.exists():
                    with open(readme_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
                        if lines:
                            scenario_info["description"] = lines[0][:200]
                        scenario_info["readme"] = content

                if commands_path.exists():
                    with open(commands_path, 'r', encoding='utf-8') as f:
                        commands_data = json.load(f)
                        scenario_info["command_count"] = len(commands_data.get("commands", []))
                        scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                        scenario_info["duration"] = commands_data.get("duration", "15 min")

                yaml_files = list(scenario_dir.glob("*.yaml")) + list(scenario_dir.glob("*.yml"))
                scenario_info["yaml_file_count"] = len(yaml_files)

                scenarios.append(scenario_info)
            except Exception as e:
                logger.error(f"Error processing Jenkins scenario {scenario_dir.name}: {e}")
                continue

        logger.info(f"Processed {len(scenarios)} Jenkins scenarios")
        return {"scenarios": scenarios}
    except Exception as e:
        logger.error(f"Fatal error in get_jenkins_scenarios: {e}", exc_info=True)
        return {"scenarios": [], "error": str(e)}

@app.get("/api/jenkins-scenarios/{scenario_id}")
async def get_jenkins_scenario(scenario_id: str):
    """Get detailed Jenkins scenario info including YAML files"""
    try:
        possible_paths = [
            Path("/jenkins-scenarios"),
            Path("/app/jenkins-scenarios"),
            Path(__file__).parent.parent.parent / "jenkins-scenarios"
        ]

        scenario_dir = None
        for base_path in possible_paths:
            test_path = base_path / scenario_id
            if test_path.exists() and test_path.is_dir():
                scenario_dir = test_path
                break

        if not scenario_dir:
            raise HTTPException(status_code=404, detail=f"Jenkins scenario '{scenario_id}' not found")

        logger.info(f"Loading Jenkins scenario from: {scenario_dir}")

        scenario_info = {
            "id": scenario_id,
            "name": scenario_id.replace("-", " ").title(),
            "readme": "",
            "commands": [],
            "yaml_files": [],
            "difficulty": "medium",
            "duration": "15 min",
            "namespace": "jenkins-scenarios"
        }

        readme_path = scenario_dir / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                scenario_info["readme"] = f.read()
        else:
            scenario_info["readme"] = "# No README available"

        commands_path = scenario_dir / "commands.json"
        if commands_path.exists():
            with open(commands_path, 'r', encoding='utf-8') as f:
                commands_data = json.load(f)
                scenario_info["commands"] = commands_data.get("commands", [])
                scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                scenario_info["duration"] = commands_data.get("duration", "15 min")

        yaml_files = []
        for pattern in ["*.yaml", "*.yml"]:
            yaml_files.extend(scenario_dir.glob(pattern))
            yaml_files.extend(scenario_dir.glob(f"**/{pattern}"))

        seen = set()
        unique_yaml = []
        for f in yaml_files:
            if f.resolve() not in seen:
                seen.add(f.resolve())
                unique_yaml.append(f)

        def yaml_sort_key(p):
            name = p.name.lower()
            if 'jenkins' in name or 'pipeline' in name:
                return (0, name)
            elif 'deployment' in name:
                return (1, name)
            elif 'service' in name:
                return (2, name)
            else:
                return (3, name)

        unique_yaml = sorted(unique_yaml, key=yaml_sort_key)

        for yaml_file in unique_yaml:
            try:
                rel_path = yaml_file.relative_to(scenario_dir)
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    scenario_info["yaml_files"].append({
                        "name": str(rel_path),
                        "content": content
                    })
            except Exception as e:
                logger.error(f"Error reading {yaml_file.name}: {e}")
                scenario_info["yaml_files"].append({
                    "name": yaml_file.name,
                    "content": f"# Error loading file: {str(e)}"
                })

        logger.info(f"Jenkins scenario {scenario_id}: {len(scenario_info['commands'])} commands, {len(scenario_info['yaml_files'])} YAML files")
        return scenario_info
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in get_jenkins_scenario: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/terraform-scenarios")
async def get_terraform_scenarios():
    """Get list of all available Terraform scenarios"""
    try:
        possible_paths = [
            Path("/terraform-scenarios"),
            Path("/app/terraform-scenarios"),
            Path(__file__).parent.parent.parent / "terraform-scenarios"
        ]

        scenarios_dir = None
        for path in possible_paths:
            if path.exists() and path.is_dir():
                scenarios_dir = path
                logger.info(f"Found Terraform scenarios at: {scenarios_dir}")
                break

        if not scenarios_dir:
            logger.warning("No Terraform scenarios directory found")
            return {"scenarios": []}

        scenarios = []
        scenario_dirs = sorted([d for d in scenarios_dir.iterdir() if d.is_dir()])
        logger.info(f"Found {len(scenario_dirs)} Terraform scenario directories")

        for scenario_dir in scenario_dirs:
            try:
                readme_path = scenario_dir / "README.md"
                commands_path = scenario_dir / "commands.json"

                scenario_info = {
                    "id": scenario_dir.name,
                    "name": scenario_dir.name.replace("-", " ").title(),
                    "description": "No description available",
                    "difficulty": "medium",
                    "duration": "20 min",
                    "readme": "",
                    "command_count": 0,
                    "namespace": "terraform-scenarios"
                }

                if readme_path.exists():
                    with open(readme_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
                        if lines:
                            scenario_info["description"] = lines[0][:200]
                        scenario_info["readme"] = content

                if commands_path.exists():
                    with open(commands_path, 'r', encoding='utf-8') as f:
                        commands_data = json.load(f)
                        scenario_info["command_count"] = len(commands_data.get("commands", []))
                        scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                        scenario_info["duration"] = commands_data.get("duration", "20 min")

                yaml_files = list(scenario_dir.glob("*.yaml")) + list(scenario_dir.glob("*.yml"))
                scenario_info["yaml_file_count"] = len(yaml_files)

                scenarios.append(scenario_info)
            except Exception as e:
                logger.error(f"Error processing Terraform scenario {scenario_dir.name}: {e}")
                continue

        logger.info(f"Processed {len(scenarios)} Terraform scenarios")
        return {"scenarios": scenarios}
    except Exception as e:
        logger.error(f"Fatal error in get_terraform_scenarios: {e}", exc_info=True)
        return {"scenarios": [], "error": str(e)}

@app.get("/api/terraform-scenarios/{scenario_id}")
async def get_terraform_scenario(scenario_id: str):
    """Get detailed Terraform scenario info including YAML files"""
    try:
        possible_paths = [
            Path("/terraform-scenarios"),
            Path("/app/terraform-scenarios"),
            Path(__file__).parent.parent.parent / "terraform-scenarios"
        ]

        scenario_dir = None
        for base_path in possible_paths:
            test_path = base_path / scenario_id
            if test_path.exists() and test_path.is_dir():
                scenario_dir = test_path
                break

        if not scenario_dir:
            raise HTTPException(status_code=404, detail=f"Terraform scenario '{scenario_id}' not found")

        logger.info(f"Loading Terraform scenario from: {scenario_dir}")

        scenario_info = {
            "id": scenario_id,
            "name": scenario_id.replace("-", " ").title(),
            "readme": "",
            "commands": [],
            "yaml_files": [],
            "difficulty": "medium",
            "duration": "20 min",
            "namespace": "terraform-scenarios"
        }

        readme_path = scenario_dir / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                scenario_info["readme"] = f.read()
        else:
            scenario_info["readme"] = "# No README available"

        commands_path = scenario_dir / "commands.json"
        if commands_path.exists():
            with open(commands_path, 'r', encoding='utf-8') as f:
                commands_data = json.load(f)
                scenario_info["commands"] = commands_data.get("commands", [])
                scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                scenario_info["duration"] = commands_data.get("duration", "20 min")

        yaml_files = []
        for pattern in ["*.yaml", "*.yml"]:
            yaml_files.extend(scenario_dir.glob(pattern))
            yaml_files.extend(scenario_dir.glob(f"**/{pattern}"))

        seen = set()
        unique_yaml = []
        for f in yaml_files:
            if f.resolve() not in seen:
                seen.add(f.resolve())
                unique_yaml.append(f)

        def yaml_sort_key(p):
            name = p.name.lower()
            if 'terraform' in name or 'provider' in name:
                return (0, name)
            elif 'main' in name:
                return (1, name)
            elif 'variables' in name:
                return (2, name)
            else:
                return (3, name)

        unique_yaml = sorted(unique_yaml, key=yaml_sort_key)

        for yaml_file in unique_yaml:
            try:
                rel_path = yaml_file.relative_to(scenario_dir)
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    scenario_info["yaml_files"].append({
                        "name": str(rel_path),
                        "content": content
                    })
            except Exception as e:
                logger.error(f"Error reading {yaml_file.name}: {e}")
                scenario_info["yaml_files"].append({
                    "name": yaml_file.name,
                    "content": f"# Error loading file: {str(e)}"
                })

        logger.info(f"Terraform scenario {scenario_id}: {len(scenario_info['commands'])} commands, {len(scenario_info['yaml_files'])} YAML files")
        return scenario_info
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in get_terraform_scenario: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/ansible-scenarios")
async def get_ansible_scenarios():
    """Get list of all available Ansible scenarios"""
    try:
        possible_paths = [
            Path("/ansible-scenarios"),
            Path("/app/ansible-scenarios"),
            Path(__file__).parent.parent.parent / "ansible-scenarios"
        ]

        scenarios_dir = None
        for path in possible_paths:
            if path.exists() and path.is_dir():
                scenarios_dir = path
                logger.info(f"Found Ansible scenarios at: {scenarios_dir}")
                break

        if not scenarios_dir:
            logger.warning("No Ansible scenarios directory found")
            return {"scenarios": []}

        scenarios = []
        scenario_dirs = sorted([d for d in scenarios_dir.iterdir() if d.is_dir()])
        logger.info(f"Found {len(scenario_dirs)} Ansible scenario directories")

        for scenario_dir in scenario_dirs:
            try:
                readme_path = scenario_dir / "README.md"
                commands_path = scenario_dir / "commands.json"

                scenario_info = {
                    "id": scenario_dir.name,
                    "name": scenario_dir.name.replace("-", " ").title(),
                    "description": "No description available",
                    "difficulty": "medium",
                    "duration": "20 min",
                    "readme": "",
                    "command_count": 0,
                    "namespace": "ansible-scenarios"
                }

                if readme_path.exists():
                    with open(readme_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
                        if lines:
                            scenario_info["description"] = lines[0][:200]
                        scenario_info["readme"] = content

                if commands_path.exists():
                    with open(commands_path, 'r', encoding='utf-8') as f:
                        commands_data = json.load(f)
                        scenario_info["command_count"] = len(commands_data.get("commands", []))
                        scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                        scenario_info["duration"] = commands_data.get("duration", "20 min")

                yaml_files = list(scenario_dir.glob("*.yaml")) + list(scenario_dir.glob("*.yml"))
                scenario_info["yaml_file_count"] = len(yaml_files)

                scenarios.append(scenario_info)
            except Exception as e:
                logger.error(f"Error processing Ansible scenario {scenario_dir.name}: {e}")
                continue

        logger.info(f"Processed {len(scenarios)} Ansible scenarios")
        return {"scenarios": scenarios}
    except Exception as e:
        logger.error(f"Fatal error in get_ansible_scenarios: {e}", exc_info=True)
        return {"scenarios": [], "error": str(e)}

@app.get("/api/ansible-scenarios/{scenario_id}")
async def get_ansible_scenario(scenario_id: str):
    """Get detailed Ansible scenario info including YAML files"""
    try:
        possible_paths = [
            Path("/ansible-scenarios"),
            Path("/app/ansible-scenarios"),
            Path(__file__).parent.parent.parent / "ansible-scenarios"
        ]

        scenario_dir = None
        for base_path in possible_paths:
            test_path = base_path / scenario_id
            if test_path.exists() and test_path.is_dir():
                scenario_dir = test_path
                break

        if not scenario_dir:
            raise HTTPException(status_code=404, detail=f"Ansible scenario '{scenario_id}' not found")

        logger.info(f"Loading Ansible scenario from: {scenario_dir}")

        scenario_info = {
            "id": scenario_id,
            "name": scenario_id.replace("-", " ").title(),
            "readme": "",
            "commands": [],
            "yaml_files": [],
            "difficulty": "medium",
            "duration": "20 min",
            "namespace": "ansible-scenarios"
        }

        readme_path = scenario_dir / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                scenario_info["readme"] = f.read()
        else:
            scenario_info["readme"] = "# No README available"

        commands_path = scenario_dir / "commands.json"
        if commands_path.exists():
            with open(commands_path, 'r', encoding='utf-8') as f:
                commands_data = json.load(f)
                scenario_info["commands"] = commands_data.get("commands", [])
                scenario_info["difficulty"] = commands_data.get("difficulty", "medium")
                scenario_info["duration"] = commands_data.get("duration", "20 min")

        yaml_files = []
        for pattern in ["*.yaml", "*.yml"]:
            yaml_files.extend(scenario_dir.glob(pattern))
            yaml_files.extend(scenario_dir.glob(f"**/{pattern}"))

        seen = set()
        unique_yaml = []
        for f in yaml_files:
            if f.resolve() not in seen:
                seen.add(f.resolve())
                unique_yaml.append(f)

        def yaml_sort_key(p):
            name = p.name.lower()
            if 'playbook' in name or 'main' in name:
                return (0, name)
            elif 'inventory' in name:
                return (1, name)
            elif 'vars' in name or 'variables' in name:
                return (2, name)
            else:
                return (3, name)

        unique_yaml = sorted(unique_yaml, key=yaml_sort_key)

        for yaml_file in unique_yaml:
            try:
                rel_path = yaml_file.relative_to(scenario_dir)
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    scenario_info["yaml_files"].append({
                        "name": str(rel_path),
                        "content": content
                    })
            except Exception as e:
                logger.error(f"Error reading {yaml_file.name}: {e}")
                scenario_info["yaml_files"].append({
                    "name": yaml_file.name,
                    "content": f"# Error loading file: {str(e)}"
                })

        logger.info(f"Ansible scenario {scenario_id}: {len(scenario_info['commands'])} commands, {len(scenario_info['yaml_files'])} YAML files")
        return scenario_info
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in get_ansible_scenario: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.on_event("shutdown")
async def shutdown_event():
    global load_test_running, load_test_task
    if load_test_running:
        load_test_running = False
        if load_test_task and not load_test_task.done():
            load_test_task.cancel()
            try:
                await load_test_task
            except asyncio.CancelledError:
                pass
    logger.info("Application shutting down")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)